{"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","gpuClass":"standard"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip3 install torch_optimizer torchmetrics\n!nvidia-smi","metadata":{"id":"8wS9TMzde74O","colab":{"base_uri":"https://localhost:8080/"},"outputId":"168c9a55-01ab-4329-ba8f-e04e7118564a","execution":{"iopub.status.busy":"2022-09-22T20:16:31.486490Z","iopub.execute_input":"2022-09-22T20:16:31.487353Z","iopub.status.idle":"2022-09-22T20:16:42.937545Z","shell.execute_reply.started":"2022-09-22T20:16:31.487312Z","shell.execute_reply":"2022-09-22T20:16:42.936122Z"},"trusted":true},"execution_count":170,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch_optimizer in /opt/conda/lib/python3.7/site-packages (0.3.0)\nRequirement already satisfied: torchmetrics in /opt/conda/lib/python3.7/site-packages (0.9.3)\nRequirement already satisfied: pytorch-ranger>=0.1.1 in /opt/conda/lib/python3.7/site-packages (from torch_optimizer) (0.1.1)\nRequirement already satisfied: torch>=1.5.0 in /opt/conda/lib/python3.7/site-packages (from torch_optimizer) (1.11.0)\nRequirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.7/site-packages (from torchmetrics) (1.21.6)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torchmetrics) (4.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from torchmetrics) (21.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->torchmetrics) (3.0.9)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mThu Sep 22 20:16:42 2022       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.82.01    Driver Version: 470.82.01    CUDA Version: 11.4     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n| N/A   41C    P0    35W / 250W |   8141MiB / 16280MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n+-----------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch_optimizer import Ranger\nfrom torchvision import datasets\nfrom torchvision import transforms,models\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.utils.data.dataloader import DataLoader\nfrom torch.utils.data import random_split\nfrom torchmetrics import Accuracy\nfrom torch.optim.lr_scheduler import CyclicLR\n\ntorch.manual_seed(43)","metadata":{"id":"DocA9o6Wal6K","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1a3a2ce0-9802-4f38-d4ec-ffdf15455956","execution":{"iopub.status.busy":"2022-09-22T20:16:42.940621Z","iopub.execute_input":"2022-09-22T20:16:42.941087Z","iopub.status.idle":"2022-09-22T20:16:42.952257Z","shell.execute_reply.started":"2022-09-22T20:16:42.941008Z","shell.execute_reply":"2022-09-22T20:16:42.951139Z"},"trusted":true},"execution_count":171,"outputs":[{"execution_count":171,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7fd8b4901ab0>"},"metadata":{}}]},{"cell_type":"code","source":"# Device configuration\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"id":"esbUB9VcarSC","execution":{"iopub.status.busy":"2022-09-22T20:16:42.953985Z","iopub.execute_input":"2022-09-22T20:16:42.954912Z","iopub.status.idle":"2022-09-22T20:16:42.962699Z","shell.execute_reply.started":"2022-09-22T20:16:42.954872Z","shell.execute_reply":"2022-09-22T20:16:42.961340Z"},"trusted":true},"execution_count":172,"outputs":[]},{"cell_type":"code","source":"\ndef target_trans(target):\n  y = -torch.ones(100)\n  y[target] = 1\n\n  return y,target ","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"CKmlDGbYauBE","outputId":"9d28f1f9-0f30-455e-b246-7b6b38b52fac","execution":{"iopub.status.busy":"2022-09-22T20:16:42.966069Z","iopub.execute_input":"2022-09-22T20:16:42.966719Z","iopub.status.idle":"2022-09-22T20:16:42.973861Z","shell.execute_reply.started":"2022-09-22T20:16:42.966664Z","shell.execute_reply":"2022-09-22T20:16:42.972546Z"},"trusted":true},"execution_count":173,"outputs":[]},{"cell_type":"code","source":"transform_train = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomCrop(size=[32,32], padding=4),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\ntransform_test = transforms.Compose([\n    transforms.CenterCrop(size=[32,32]),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\ndataset = datasets.CIFAR100(root='data/', download=True, transform=transform_train,target_transform=target_trans)\ntest_dataset = datasets.CIFAR100(root='data/', train=False, transform=transform_test,target_transform=target_trans)\n\n\nval_size = 5000\ntrain_size = len(dataset) - val_size\ntrain_ds, val_ds = random_split(dataset, [train_size, val_size])\nbatch_size=256\n\ntrain_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4)\nvalid_loader = DataLoader(val_ds, batch_size, num_workers=4)\ntest_loader = DataLoader(test_dataset, batch_size, num_workers=4)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RvWoz_Vsaxv6","outputId":"a1132e7d-bb51-41a3-9a4f-77898ac34945","execution":{"iopub.status.busy":"2022-09-22T20:16:42.975979Z","iopub.execute_input":"2022-09-22T20:16:42.976355Z","iopub.status.idle":"2022-09-22T20:16:44.548387Z","shell.execute_reply.started":"2022-09-22T20:16:42.976319Z","shell.execute_reply":"2022-09-22T20:16:44.547203Z"},"trusted":true},"execution_count":174,"outputs":[{"name":"stdout","text":"Files already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"code","source":"class Hinge_Loss(torch.nn.Module):\n    \n    def __init__(self):\n        super(Hinge_Loss,self).__init__()\n        \n    def forward(self,y_p,y_t):\n\n        temp = 1 - y_p * y_t\n        \n        zero = torch.zeros(y_p.size()[0],y_p.size()[1])\n        zero = zero.cuda()\n        clamp = torch.max(temp,zero)\n    \n        total_loss = torch.sum(clamp)/y_p.size()[0]\n        return total_loss","metadata":{"id":"IARmmjZTbGMx","execution":{"iopub.status.busy":"2022-09-22T20:16:44.549825Z","iopub.execute_input":"2022-09-22T20:16:44.550222Z","iopub.status.idle":"2022-09-22T20:16:44.557127Z","shell.execute_reply.started":"2022-09-22T20:16:44.550174Z","shell.execute_reply":"2022-09-22T20:16:44.556034Z"},"trusted":true},"execution_count":175,"outputs":[]},{"cell_type":"code","source":"num_classes = 100\nnum_epochs = 100\n","metadata":{"id":"ZQc7HygQeCUT","execution":{"iopub.status.busy":"2022-09-22T20:16:44.558771Z","iopub.execute_input":"2022-09-22T20:16:44.559461Z","iopub.status.idle":"2022-09-22T20:16:44.569265Z","shell.execute_reply.started":"2022-09-22T20:16:44.559402Z","shell.execute_reply":"2022-09-22T20:16:44.568198Z"},"trusted":true},"execution_count":176,"outputs":[]},{"cell_type":"code","source":"class VGGForCiFar100(nn.Module):\n  def __init__(self, hid_dim=5000, dropout=0.5, n_classes=100, use_fc=True, freeze=False):\n    super().__init__()\n    self.vgg = models.vgg16(pretrained=True)\n    if not use_fc:\n      self.vgg.classifier = nn.Linear(512 * 7 * 7, n_classes)\n    else:\n      self.vgg.classifier = nn.Sequential(\n              nn.Linear(512 * 7 * 7, 5000),\n              nn.ReLU(True),\n              nn.Dropout(p=dropout),\n              #nn.Linear(4096, 4096),\n              #nn.ReLU(True),\n              #nn.Dropout(p=dropout),\n              nn.Linear(5000, n_classes),\n          )\n      \n    if freeze:\n      for param in self.vgg.features.parameters():\n        param.requires_grad = False\n      for param in self.vgg.avg_pool.parameters():\n        param.requires_grad = False\n      for param in self.vgg.flatten.parameters():\n        param.requires_grad = False\n    \n\n  def forward(self, x):\n    return self.vgg(x)","metadata":{"id":"OLP6Q6yxauMw","execution":{"iopub.status.busy":"2022-09-22T20:16:44.570967Z","iopub.execute_input":"2022-09-22T20:16:44.571374Z","iopub.status.idle":"2022-09-22T20:16:44.583055Z","shell.execute_reply.started":"2022-09-22T20:16:44.571334Z","shell.execute_reply":"2022-09-22T20:16:44.581919Z"},"trusted":true},"execution_count":177,"outputs":[]},{"cell_type":"code","source":"\nmodel = VGGForCiFar100(n_classes=num_classes).to(device)\ncriterion = Hinge_Loss().to(device)\naccuracy = Accuracy(num_classes=num_classes).to(device)\noptimizer = Ranger(model.parameters(), lr=1e-3, weight_decay=1e-4) \nscheduler = CyclicLR(optimizer, base_lr=1e-6, max_lr=1e-3, step_size_up=len(train_loader)//2, cycle_momentum=False)\n","metadata":{"id":"0c42xudTbEsB","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6827f613-4f71-428c-e673-bcada3ee6030","execution":{"iopub.status.busy":"2022-09-22T20:16:44.584539Z","iopub.execute_input":"2022-09-22T20:16:44.585204Z","iopub.status.idle":"2022-09-22T20:16:48.742761Z","shell.execute_reply.started":"2022-09-22T20:16:44.585166Z","shell.execute_reply":"2022-09-22T20:16:48.741398Z"},"trusted":true},"execution_count":178,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"etxLVu_JauWo","outputId":"f7147aa0-5626-4c22-9f07-b173ef58fc63","execution":{"iopub.status.busy":"2022-09-22T20:16:48.746941Z","iopub.execute_input":"2022-09-22T20:16:48.747407Z","iopub.status.idle":"2022-09-22T20:16:48.755044Z","shell.execute_reply.started":"2022-09-22T20:16:48.747369Z","shell.execute_reply":"2022-09-22T20:16:48.753835Z"},"trusted":true},"execution_count":179,"outputs":[{"execution_count":179,"output_type":"execute_result","data":{"text/plain":"VGGForCiFar100(\n  (vgg): VGG(\n    (features): Sequential(\n      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU(inplace=True)\n      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (3): ReLU(inplace=True)\n      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (6): ReLU(inplace=True)\n      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (8): ReLU(inplace=True)\n      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (11): ReLU(inplace=True)\n      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (13): ReLU(inplace=True)\n      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (15): ReLU(inplace=True)\n      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (18): ReLU(inplace=True)\n      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (20): ReLU(inplace=True)\n      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (22): ReLU(inplace=True)\n      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (25): ReLU(inplace=True)\n      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (27): ReLU(inplace=True)\n      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (29): ReLU(inplace=True)\n      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    )\n    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n    (classifier): Sequential(\n      (0): Linear(in_features=25088, out_features=5000, bias=True)\n      (1): ReLU(inplace=True)\n      (2): Dropout(p=0.5, inplace=False)\n      (3): Linear(in_features=5000, out_features=100, bias=True)\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"\ndef get_accuracy(output, target):\n\n  batch_size = target.size(0)\n  correct=0\n\n  pred = output.max(dim=1)[1]\n\n  correct = pred==target\n\n  acc = correct.float().sum(0)\n\n  return acc/batch_size\n","metadata":{"id":"_XEwQBgWcMYQ","execution":{"iopub.status.busy":"2022-09-22T20:16:48.757056Z","iopub.execute_input":"2022-09-22T20:16:48.757929Z","iopub.status.idle":"2022-09-22T20:16:48.766989Z","shell.execute_reply.started":"2022-09-22T20:16:48.757885Z","shell.execute_reply":"2022-09-22T20:16:48.765686Z"},"trusted":true},"execution_count":180,"outputs":[]},{"cell_type":"code","source":"total_train_step = len(train_loader)\n#print(total_train_step)\ntotal_val_step=len(valid_loader)\nBEST_VAL_METRIC = 0\nBEST_MODEL = None\n\nfor epoch in range(1, num_epochs+1):\n\n    train_loss=0\n    train_acc=0.0\n    model.train()\n\n    for i, (images, target) in enumerate(train_loader, 1):\n\n        y_trans = target[0]\n        y_true = target[1]\n\n        # Move tensors to the configured device\n        images = images.to(device)\n        y_true = y_true.to(device)\n        y_trans = y_trans.to(device)\n        \n        # Forward pass\n        outputs = model(images)\n        loss = criterion(outputs, y_trans)\n\n        train_loss += loss\n        #train_acc += get_accuracy(outputs, y_true)\n        train_acc += accuracy(outputs, y_true)\n        \n        \n        # Backward and optimize\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n        optimizer.zero_grad()\n\n    print(f'Epoch [{epoch}/{num_epochs}] - Loss: {(train_loss/total_train_step):.4f}, Accuracy: {(train_acc/total_train_step):.4f}')\n\n    model.eval() \n    # Validation\n    with torch.no_grad():\n        val_acc = 0\n        val_loss=0\n        for i, (images, target) in enumerate(valid_loader, 1):\n\n            y_trans = target[0]\n            y_true = target[1]\n\n            # Move tensors to the configured device\n            images = images.to(device)\n            y_true = y_true.to(device)\n            y_trans = y_trans.to(device)\n\n            outputs = model(images)\n            val_loss += criterion(outputs, y_trans)\n            #val_acc += get_accuracy(outputs, y_true)\n            val_acc += accuracy(outputs, y_true)\n\n    if val_acc/total_val_step > BEST_VAL_METRIC:\n        BEST_VAL_METRIC = val_acc/total_val_step\n        BEST_MODEL = model.state_dict() \n\n    print(f'Accuracy of the network on the 5000 validation images: {(val_acc/total_val_step):.4f}, loss: {(val_loss/total_val_step):.4f}') ","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eStoYUJ2cmCt","outputId":"6025dae7-b145-4f47-eca0-be1814137a41","execution":{"iopub.status.busy":"2022-09-22T20:16:48.769019Z","iopub.execute_input":"2022-09-22T20:16:48.769496Z","iopub.status.idle":"2022-09-22T21:07:13.079411Z","shell.execute_reply.started":"2022-09-22T20:16:48.769415Z","shell.execute_reply":"2022-09-22T21:07:13.077023Z"},"trusted":true},"execution_count":181,"outputs":[{"name":"stdout","text":"Epoch [1/100] - Loss: 11.2977, Accuracy: 0.0388\nAccuracy of the network on the 5000 validation images: 0.1498, loss: 2.3833\nEpoch [2/100] - Loss: 2.3892, Accuracy: 0.0819\nAccuracy of the network on the 5000 validation images: 0.2240, loss: 2.2210\nEpoch [3/100] - Loss: 2.2374, Accuracy: 0.1305\nAccuracy of the network on the 5000 validation images: 0.2656, loss: 2.1239\nEpoch [4/100] - Loss: 2.1659, Accuracy: 0.1701\nAccuracy of the network on the 5000 validation images: 0.2877, loss: 2.0636\nEpoch [5/100] - Loss: 2.0689, Accuracy: 0.2226\nAccuracy of the network on the 5000 validation images: 0.3299, loss: 1.9896\nEpoch [6/100] - Loss: 2.1244, Accuracy: 0.2219\nAccuracy of the network on the 5000 validation images: 0.2550, loss: 2.0180\nEpoch [7/100] - Loss: 1.9617, Accuracy: 0.2427\nAccuracy of the network on the 5000 validation images: 0.3411, loss: 1.8839\nEpoch [8/100] - Loss: 1.8773, Accuracy: 0.2884\nAccuracy of the network on the 5000 validation images: 0.3820, loss: 1.8306\nEpoch [9/100] - Loss: 1.8223, Accuracy: 0.3187\nAccuracy of the network on the 5000 validation images: 0.3996, loss: 1.8011\nEpoch [10/100] - Loss: 1.7784, Accuracy: 0.3423\nAccuracy of the network on the 5000 validation images: 0.4039, loss: 1.7795\nEpoch [11/100] - Loss: 1.7679, Accuracy: 0.3537\nAccuracy of the network on the 5000 validation images: 0.4032, loss: 1.7501\nEpoch [12/100] - Loss: 1.7045, Accuracy: 0.3746\nAccuracy of the network on the 5000 validation images: 0.4434, loss: 1.7095\nEpoch [13/100] - Loss: 1.6822, Accuracy: 0.3952\nAccuracy of the network on the 5000 validation images: 0.4376, loss: 1.7056\nEpoch [14/100] - Loss: 1.6868, Accuracy: 0.3981\nAccuracy of the network on the 5000 validation images: 0.4267, loss: 1.6880\nEpoch [15/100] - Loss: 1.6210, Accuracy: 0.4132\nAccuracy of the network on the 5000 validation images: 0.4505, loss: 1.6666\nEpoch [16/100] - Loss: 1.6178, Accuracy: 0.4275\nAccuracy of the network on the 5000 validation images: 0.4557, loss: 1.6470\nEpoch [17/100] - Loss: 1.5591, Accuracy: 0.4425\nAccuracy of the network on the 5000 validation images: 0.4766, loss: 1.6294\nEpoch [18/100] - Loss: 1.5365, Accuracy: 0.4552\nAccuracy of the network on the 5000 validation images: 0.4758, loss: 1.6032\nEpoch [19/100] - Loss: 1.5108, Accuracy: 0.4695\nAccuracy of the network on the 5000 validation images: 0.4771, loss: 1.5962\nEpoch [20/100] - Loss: 1.4781, Accuracy: 0.4804\nAccuracy of the network on the 5000 validation images: 0.4895, loss: 1.5854\nEpoch [21/100] - Loss: 1.4838, Accuracy: 0.4785\nAccuracy of the network on the 5000 validation images: 0.4833, loss: 1.5763\nEpoch [22/100] - Loss: 1.4326, Accuracy: 0.4933\nAccuracy of the network on the 5000 validation images: 0.5019, loss: 1.5340\nEpoch [23/100] - Loss: 1.5799, Accuracy: 0.4805\nAccuracy of the network on the 5000 validation images: 0.4669, loss: 1.5939\nEpoch [24/100] - Loss: 1.4156, Accuracy: 0.4927\nAccuracy of the network on the 5000 validation images: 0.5061, loss: 1.5494\nEpoch [25/100] - Loss: 1.3538, Accuracy: 0.5211\nAccuracy of the network on the 5000 validation images: 0.5138, loss: 1.5248\nEpoch [26/100] - Loss: 1.3319, Accuracy: 0.5308\nAccuracy of the network on the 5000 validation images: 0.5128, loss: 1.5226\nEpoch [27/100] - Loss: 1.3164, Accuracy: 0.5381\nAccuracy of the network on the 5000 validation images: 0.5156, loss: 1.4755\nEpoch [28/100] - Loss: 1.2902, Accuracy: 0.5442\nAccuracy of the network on the 5000 validation images: 0.5144, loss: 1.5067\nEpoch [29/100] - Loss: 1.2648, Accuracy: 0.5530\nAccuracy of the network on the 5000 validation images: 0.5175, loss: 1.4790\nEpoch [30/100] - Loss: 1.2437, Accuracy: 0.5622\nAccuracy of the network on the 5000 validation images: 0.5264, loss: 1.4657\nEpoch [31/100] - Loss: 1.2280, Accuracy: 0.5678\nAccuracy of the network on the 5000 validation images: 0.5305, loss: 1.4835\nEpoch [32/100] - Loss: 1.2346, Accuracy: 0.5680\nAccuracy of the network on the 5000 validation images: 0.5257, loss: 1.4848\nEpoch [33/100] - Loss: 1.1930, Accuracy: 0.5799\nAccuracy of the network on the 5000 validation images: 0.5331, loss: 1.4508\nEpoch [34/100] - Loss: 1.1895, Accuracy: 0.5837\nAccuracy of the network on the 5000 validation images: 0.5387, loss: 1.4572\nEpoch [35/100] - Loss: 1.1608, Accuracy: 0.5921\nAccuracy of the network on the 5000 validation images: 0.5481, loss: 1.4515\nEpoch [36/100] - Loss: 1.1422, Accuracy: 0.5956\nAccuracy of the network on the 5000 validation images: 0.5446, loss: 1.4540\nEpoch [37/100] - Loss: 1.1520, Accuracy: 0.5987\nAccuracy of the network on the 5000 validation images: 0.5365, loss: 1.4477\nEpoch [38/100] - Loss: 1.1142, Accuracy: 0.6045\nAccuracy of the network on the 5000 validation images: 0.5418, loss: 1.4531\nEpoch [39/100] - Loss: 1.1086, Accuracy: 0.6074\nAccuracy of the network on the 5000 validation images: 0.5411, loss: 1.4542\nEpoch [40/100] - Loss: 1.0962, Accuracy: 0.6110\nAccuracy of the network on the 5000 validation images: 0.5422, loss: 1.4602\nEpoch [41/100] - Loss: 1.0873, Accuracy: 0.6151\nAccuracy of the network on the 5000 validation images: 0.5472, loss: 1.4464\nEpoch [42/100] - Loss: 1.0791, Accuracy: 0.6201\nAccuracy of the network on the 5000 validation images: 0.5550, loss: 1.4282\nEpoch [43/100] - Loss: 1.0710, Accuracy: 0.6195\nAccuracy of the network on the 5000 validation images: 0.5460, loss: 1.4430\nEpoch [44/100] - Loss: 1.0645, Accuracy: 0.6226\nAccuracy of the network on the 5000 validation images: 0.5381, loss: 1.4548\nEpoch [45/100] - Loss: 1.0466, Accuracy: 0.6293\nAccuracy of the network on the 5000 validation images: 0.5464, loss: 1.4516\nEpoch [46/100] - Loss: 1.0212, Accuracy: 0.6351\nAccuracy of the network on the 5000 validation images: 0.5574, loss: 1.4279\nEpoch [47/100] - Loss: 1.0160, Accuracy: 0.6370\nAccuracy of the network on the 5000 validation images: 0.5484, loss: 1.4417\nEpoch [48/100] - Loss: 1.0096, Accuracy: 0.6378\nAccuracy of the network on the 5000 validation images: 0.5585, loss: 1.4136\nEpoch [49/100] - Loss: 0.9998, Accuracy: 0.6413\nAccuracy of the network on the 5000 validation images: 0.5591, loss: 1.4186\nEpoch [50/100] - Loss: 0.9847, Accuracy: 0.6452\nAccuracy of the network on the 5000 validation images: 0.5647, loss: 1.3877\nEpoch [51/100] - Loss: 0.9710, Accuracy: 0.6497\nAccuracy of the network on the 5000 validation images: 0.5516, loss: 1.4351\nEpoch [52/100] - Loss: 0.9623, Accuracy: 0.6543\nAccuracy of the network on the 5000 validation images: 0.5623, loss: 1.4214\nEpoch [53/100] - Loss: 0.9710, Accuracy: 0.6515\nAccuracy of the network on the 5000 validation images: 0.5673, loss: 1.4180\nEpoch [54/100] - Loss: 0.9648, Accuracy: 0.6549\nAccuracy of the network on the 5000 validation images: 0.5628, loss: 1.4241\nEpoch [55/100] - Loss: 0.9577, Accuracy: 0.6594\nAccuracy of the network on the 5000 validation images: 0.5524, loss: 1.4402\nEpoch [56/100] - Loss: 0.9284, Accuracy: 0.6687\nAccuracy of the network on the 5000 validation images: 0.5602, loss: 1.4356\nEpoch [57/100] - Loss: 0.9326, Accuracy: 0.6657\nAccuracy of the network on the 5000 validation images: 0.5755, loss: 1.3982\nEpoch [58/100] - Loss: 0.9349, Accuracy: 0.6652\nAccuracy of the network on the 5000 validation images: 0.5676, loss: 1.4172\nEpoch [59/100] - Loss: 0.9200, Accuracy: 0.6710\nAccuracy of the network on the 5000 validation images: 0.5741, loss: 1.4032\nEpoch [60/100] - Loss: 0.9125, Accuracy: 0.6731\nAccuracy of the network on the 5000 validation images: 0.5551, loss: 1.4322\nEpoch [61/100] - Loss: 0.9121, Accuracy: 0.6716\nAccuracy of the network on the 5000 validation images: 0.5625, loss: 1.4032\nEpoch [62/100] - Loss: 0.9075, Accuracy: 0.6736\nAccuracy of the network on the 5000 validation images: 0.5649, loss: 1.4266\nEpoch [63/100] - Loss: 0.9037, Accuracy: 0.6740\nAccuracy of the network on the 5000 validation images: 0.5580, loss: 1.4245\nEpoch [64/100] - Loss: 0.8979, Accuracy: 0.6769\nAccuracy of the network on the 5000 validation images: 0.5690, loss: 1.3933\nEpoch [65/100] - Loss: 0.8824, Accuracy: 0.6808\nAccuracy of the network on the 5000 validation images: 0.5706, loss: 1.4034\nEpoch [66/100] - Loss: 0.8660, Accuracy: 0.6842\nAccuracy of the network on the 5000 validation images: 0.5652, loss: 1.4271\nEpoch [67/100] - Loss: 0.8703, Accuracy: 0.6823\nAccuracy of the network on the 5000 validation images: 0.5665, loss: 1.4077\nEpoch [68/100] - Loss: 0.8533, Accuracy: 0.6914\nAccuracy of the network on the 5000 validation images: 0.5734, loss: 1.3955\nEpoch [69/100] - Loss: 0.8805, Accuracy: 0.6811\nAccuracy of the network on the 5000 validation images: 0.5537, loss: 1.4402\nEpoch [70/100] - Loss: 0.8532, Accuracy: 0.6902\nAccuracy of the network on the 5000 validation images: 0.5636, loss: 1.4226\nEpoch [71/100] - Loss: 0.8599, Accuracy: 0.6872\nAccuracy of the network on the 5000 validation images: 0.5663, loss: 1.3972\nEpoch [72/100] - Loss: 0.8640, Accuracy: 0.6900\nAccuracy of the network on the 5000 validation images: 0.5679, loss: 1.4182\nEpoch [73/100] - Loss: 0.8473, Accuracy: 0.6967\nAccuracy of the network on the 5000 validation images: 0.5752, loss: 1.3932\nEpoch [74/100] - Loss: 0.8308, Accuracy: 0.6980\nAccuracy of the network on the 5000 validation images: 0.5692, loss: 1.4268\nEpoch [75/100] - Loss: 0.8335, Accuracy: 0.6975\nAccuracy of the network on the 5000 validation images: 0.5698, loss: 1.4419\nEpoch [76/100] - Loss: 0.8480, Accuracy: 0.6926\nAccuracy of the network on the 5000 validation images: 0.5642, loss: 1.4491\nEpoch [77/100] - Loss: 0.8355, Accuracy: 0.6973\nAccuracy of the network on the 5000 validation images: 0.5712, loss: 1.4113\nEpoch [78/100] - Loss: 0.8238, Accuracy: 0.6988\nAccuracy of the network on the 5000 validation images: 0.5687, loss: 1.4428\nEpoch [79/100] - Loss: 0.8150, Accuracy: 0.7053\nAccuracy of the network on the 5000 validation images: 0.5687, loss: 1.4066\nEpoch [80/100] - Loss: 0.8394, Accuracy: 0.6954\nAccuracy of the network on the 5000 validation images: 0.5669, loss: 1.4517\nEpoch [81/100] - Loss: 0.8186, Accuracy: 0.7057\nAccuracy of the network on the 5000 validation images: 0.5724, loss: 1.4199\nEpoch [82/100] - Loss: 0.8021, Accuracy: 0.7100\nAccuracy of the network on the 5000 validation images: 0.5810, loss: 1.4146\nEpoch [83/100] - Loss: 0.7909, Accuracy: 0.7138\nAccuracy of the network on the 5000 validation images: 0.5689, loss: 1.4383\nEpoch [84/100] - Loss: 0.7882, Accuracy: 0.7146\nAccuracy of the network on the 5000 validation images: 0.5732, loss: 1.4090\nEpoch [85/100] - Loss: 0.7758, Accuracy: 0.7176\nAccuracy of the network on the 5000 validation images: 0.5746, loss: 1.4004\nEpoch [86/100] - Loss: 0.7799, Accuracy: 0.7132\nAccuracy of the network on the 5000 validation images: 0.5714, loss: 1.4025\nEpoch [87/100] - Loss: 0.8143, Accuracy: 0.7069\nAccuracy of the network on the 5000 validation images: 0.5665, loss: 1.4360\nEpoch [88/100] - Loss: 0.7847, Accuracy: 0.7148\nAccuracy of the network on the 5000 validation images: 0.5649, loss: 1.4407\nEpoch [89/100] - Loss: 0.7917, Accuracy: 0.7153\nAccuracy of the network on the 5000 validation images: 0.5825, loss: 1.3658\nEpoch [90/100] - Loss: 0.7751, Accuracy: 0.7185\nAccuracy of the network on the 5000 validation images: 0.5737, loss: 1.4146\nEpoch [91/100] - Loss: 0.7533, Accuracy: 0.7244\nAccuracy of the network on the 5000 validation images: 0.5747, loss: 1.4174\nEpoch [92/100] - Loss: 0.7770, Accuracy: 0.7182\nAccuracy of the network on the 5000 validation images: 0.5734, loss: 1.4341\nEpoch [93/100] - Loss: 0.7806, Accuracy: 0.7199\nAccuracy of the network on the 5000 validation images: 0.5751, loss: 1.4485\nEpoch [94/100] - Loss: 0.7729, Accuracy: 0.7197\nAccuracy of the network on the 5000 validation images: 0.5722, loss: 1.4158\nEpoch [95/100] - Loss: 0.7533, Accuracy: 0.7240\nAccuracy of the network on the 5000 validation images: 0.5621, loss: 1.4675\nEpoch [96/100] - Loss: 0.8032, Accuracy: 0.7090\nAccuracy of the network on the 5000 validation images: 0.5492, loss: 1.4661\nEpoch [97/100] - Loss: 0.8077, Accuracy: 0.7103\nAccuracy of the network on the 5000 validation images: 0.5709, loss: 1.4400\nEpoch [98/100] - Loss: 0.7632, Accuracy: 0.7241\nAccuracy of the network on the 5000 validation images: 0.5697, loss: 1.4104\nEpoch [99/100] - Loss: 0.7489, Accuracy: 0.7259\nAccuracy of the network on the 5000 validation images: 0.5732, loss: 1.4260\nEpoch [100/100] - Loss: 0.7863, Accuracy: 0.7160\nAccuracy of the network on the 5000 validation images: 0.5504, loss: 1.4712\n","output_type":"stream"}]},{"cell_type":"code","source":"#Testing\nmodel.load_state_dict(BEST_MODEL)\n\ntotal_test_step=len(test_loader)\n\nwith torch.no_grad():\n    test_acc=0\n    test_loss=0\n\n    for i, (images, target) in enumerate(test_loader, 1):\n        \n        y_trans = target[0]\n        y_true = target[1]\n        \n        images = images.to(device)\n        y_true = y_true.to(device)\n        y_trans = y_trans.to(device)\n\n        # Forward pass\n        outputs = model(images)\n        \n        # Loss\n        test_loss += criterion(outputs,y_trans)\n        test_acc += accuracy(outputs, y_true)\n\n    print(f'Accuracy of the network on test images: {(test_acc/total_test_step):.4f}, loss: {(test_loss/total_test_step):.4f}')","metadata":{"id":"5Bv9EVemdb8q","execution":{"iopub.status.busy":"2022-09-22T21:07:13.081452Z","iopub.execute_input":"2022-09-22T21:07:13.082222Z","iopub.status.idle":"2022-09-22T21:07:17.269852Z","shell.execute_reply.started":"2022-09-22T21:07:13.082172Z","shell.execute_reply":"2022-09-22T21:07:17.268237Z"},"trusted":true},"execution_count":182,"outputs":[{"name":"stdout","text":"Accuracy of the network on test images: 0.5760, loss: 1.4057\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"id":"Lqw6WDBqczFO"},"execution_count":null,"outputs":[]}]}