{
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ruheena-S/Hierarchical-classification-Loss-Functions-in-Image-Classification/blob/main/OVA_ResNet18_CIFAR100.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torch_optimizer torchmetrics\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "8wS9TMzde74O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5da6503d-1915-4c01-fa0c-379ae7a24e63",
        "execution": {
          "iopub.status.busy": "2022-09-22T20:16:31.486490Z",
          "iopub.execute_input": "2022-09-22T20:16:31.487353Z",
          "iopub.status.idle": "2022-09-22T20:16:42.937545Z",
          "shell.execute_reply.started": "2022-09-22T20:16:31.487312Z",
          "shell.execute_reply": "2022-09-22T20:16:42.936122Z"
        },
        "trusted": true
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch_optimizer in /usr/local/lib/python3.9/dist-packages (0.3.0)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.9/dist-packages (0.11.4)\n",
            "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.9/dist-packages (from torch_optimizer) (1.13.1+cu116)\n",
            "Requirement already satisfied: pytorch-ranger>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from torch_optimizer) (0.1.1)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.5.0->torch_optimizer) (4.5.0)\n",
            "Mon Mar 13 10:01:19 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   77C    P0    34W /  70W |   2993MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_optimizer import Ranger\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms,models\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "from torchmetrics import Accuracy\n",
        "from torch.optim.lr_scheduler import CyclicLR\n",
        "\n",
        "torch.manual_seed(43)"
      ],
      "metadata": {
        "id": "DocA9o6Wal6K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af05eece-331b-4e0b-d079-22f95ff17fd6",
        "execution": {
          "iopub.status.busy": "2022-09-22T20:16:42.940621Z",
          "iopub.execute_input": "2022-09-22T20:16:42.941087Z",
          "iopub.status.idle": "2022-09-22T20:16:42.952257Z",
          "shell.execute_reply.started": "2022-09-22T20:16:42.941008Z",
          "shell.execute_reply": "2022-09-22T20:16:42.951139Z"
        },
        "trusted": true
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f60f4baa950>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "esbUB9VcarSC",
        "execution": {
          "iopub.status.busy": "2022-09-22T20:16:42.953985Z",
          "iopub.execute_input": "2022-09-22T20:16:42.954912Z",
          "iopub.status.idle": "2022-09-22T20:16:42.962699Z",
          "shell.execute_reply.started": "2022-09-22T20:16:42.954872Z",
          "shell.execute_reply": "2022-09-22T20:16:42.961340Z"
        },
        "trusted": true
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def target_trans(target):\n",
        "  y = -torch.ones(100)\n",
        "  y[target] = 1\n",
        "\n",
        "  return y,target "
      ],
      "metadata": {
        "id": "CKmlDGbYauBE",
        "execution": {
          "iopub.status.busy": "2022-09-22T20:16:42.966069Z",
          "iopub.execute_input": "2022-09-22T20:16:42.966719Z",
          "iopub.status.idle": "2022-09-22T20:16:42.973861Z",
          "shell.execute_reply.started": "2022-09-22T20:16:42.966664Z",
          "shell.execute_reply": "2022-09-22T20:16:42.972546Z"
        },
        "trusted": true
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transforms for data augmentation\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761])\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5071, 0.4867, 0.4408], std=[0.2675, 0.2565, 0.2761])\n",
        "])\n",
        "\n",
        "dataset = datasets.CIFAR100(root='data/', download=True, transform=transform_train,target_transform=target_trans)\n",
        "test_dataset = datasets.CIFAR100(root='data/', train=False, transform=transform_test,target_transform=target_trans)\n",
        "\n",
        "\n",
        "val_size = 5000\n",
        "train_size = len(dataset) - val_size\n",
        "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
        "batch_size=256\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4)\n",
        "valid_loader = DataLoader(val_ds, batch_size, num_workers=4)\n",
        "test_loader = DataLoader(test_dataset, batch_size, num_workers=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvWoz_Vsaxv6",
        "outputId": "b13aa0e7-edca-4d00-c1fc-88a298694016",
        "execution": {
          "iopub.status.busy": "2022-09-22T20:16:42.975979Z",
          "iopub.execute_input": "2022-09-22T20:16:42.976355Z",
          "iopub.status.idle": "2022-09-22T20:16:44.548387Z",
          "shell.execute_reply.started": "2022-09-22T20:16:42.976319Z",
          "shell.execute_reply": "2022-09-22T20:16:44.547203Z"
        },
        "trusted": true
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Hinge_Loss(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(Hinge_Loss,self).__init__()\n",
        "        \n",
        "    def forward(self,y_p,y_t):\n",
        "\n",
        "        temp = 1 - y_p * y_t\n",
        "        \n",
        "        zero = torch.zeros(y_p.size()[0],y_p.size()[1])\n",
        "        zero = zero.cuda()\n",
        "        clamp = torch.max(temp,zero)\n",
        "    \n",
        "        total_loss = torch.sum(clamp)/y_p.size()[0]\n",
        "        return total_loss"
      ],
      "metadata": {
        "id": "IARmmjZTbGMx",
        "execution": {
          "iopub.status.busy": "2022-09-22T20:16:44.549825Z",
          "iopub.execute_input": "2022-09-22T20:16:44.550222Z",
          "iopub.status.idle": "2022-09-22T20:16:44.557127Z",
          "shell.execute_reply.started": "2022-09-22T20:16:44.550174Z",
          "shell.execute_reply": "2022-09-22T20:16:44.556034Z"
        },
        "trusted": true
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 100\n",
        "num_epochs = 10\n"
      ],
      "metadata": {
        "id": "ZQc7HygQeCUT",
        "execution": {
          "iopub.status.busy": "2022-09-22T20:16:44.558771Z",
          "iopub.execute_input": "2022-09-22T20:16:44.559461Z",
          "iopub.status.idle": "2022-09-22T20:16:44.569265Z",
          "shell.execute_reply.started": "2022-09-22T20:16:44.559402Z",
          "shell.execute_reply": "2022-09-22T20:16:44.568198Z"
        },
        "trusted": true
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained ResNet18 model\n",
        "resnet18 = models.resnet18(pretrained=True)\n",
        "resnet18.conv1 = nn.Conv2d(3, 64, kernel_size = (3,3), padding = (1, 1), bias = False)\n",
        "resnet18.maxpool = nn.Identity()\n",
        "\n",
        "# Freeze all layers except for the last one\n",
        "for param in resnet18.parameters():\n",
        "    param.requires_grad = True\n",
        "resnet18.fc = nn.Linear(512, 100)\n",
        "\n",
        "resnet18.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9WXMBCsW6mN",
        "outputId": "afac1ca9-4576-4a71-c98b-1b554cd7354f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): Identity()\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=100, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss function and optimizer\n",
        "\n",
        "criterion = Hinge_Loss().to(device)\n",
        "accuracy = Accuracy(task=\"multiclass\",num_classes=num_classes).to(device)\n",
        "optimizer = Ranger(resnet18.parameters(), lr=1e-3, weight_decay=1e-4) \n",
        "scheduler = CyclicLR(optimizer, base_lr=1e-6, max_lr=1e-3, step_size_up=len(train_loader)//2, cycle_momentum=False)\n",
        "\n",
        "# optimizer = optim.SGD(resnet18.fc.parameters(), lr=0.001, momentum=0.9)\n",
        "#optimizer = Ranger(resnet18.parameters(), lr=0.001, weight_decay=0.005) \n",
        "#optimizer = optim.Adam(resnet18.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "0c42xudTbEsB",
        "execution": {
          "iopub.status.busy": "2022-09-22T20:16:44.584539Z",
          "iopub.execute_input": "2022-09-22T20:16:44.585204Z",
          "iopub.status.idle": "2022-09-22T20:16:48.742761Z",
          "shell.execute_reply.started": "2022-09-22T20:16:44.585166Z",
          "shell.execute_reply": "2022-09-22T20:16:48.741398Z"
        },
        "trusted": true
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_accuracy(output, target):\n",
        "\n",
        "  batch_size = target.size(0)\n",
        "  correct=0\n",
        "\n",
        "  pred = output.max(dim=1)[1]\n",
        "\n",
        "  correct = pred==target\n",
        "\n",
        "  acc = correct.float().sum(0)\n",
        "\n",
        "  return acc/batch_size\n"
      ],
      "metadata": {
        "id": "_XEwQBgWcMYQ",
        "execution": {
          "iopub.status.busy": "2022-09-22T20:16:48.757056Z",
          "iopub.execute_input": "2022-09-22T20:16:48.757929Z",
          "iopub.status.idle": "2022-09-22T20:16:48.766989Z",
          "shell.execute_reply.started": "2022-09-22T20:16:48.757885Z",
          "shell.execute_reply": "2022-09-22T20:16:48.765686Z"
        },
        "trusted": true
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 40\n",
        "total_train_step = len(train_loader)\n",
        "#print(total_train_step)\n",
        "total_val_step=len(valid_loader)\n",
        "BEST_VAL_METRIC = 0\n",
        "BEST_MODEL = None\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "\n",
        "    train_loss=0\n",
        "    train_acc=0.0\n",
        "    resnet18.train()\n",
        "\n",
        "    for i, (images, target) in enumerate(train_loader, 1):\n",
        "\n",
        "        y_trans = target[0]\n",
        "        y_true = target[1]\n",
        "\n",
        "        # Move tensors to the configured device\n",
        "        images = images.to(device)\n",
        "        y_true = y_true.to(device)\n",
        "        y_trans = y_trans.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = resnet18(images)\n",
        "        loss = criterion(outputs, y_trans)\n",
        "\n",
        "        train_loss += loss\n",
        "        #train_acc += get_accuracy(outputs, y_true)\n",
        "        train_acc += accuracy(outputs, y_true)\n",
        "        \n",
        "        \n",
        "        # Backward and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    print(f'Epoch [{epoch}/{num_epochs}] - Loss: {(train_loss/total_train_step):.4f}, Accuracy: {(train_acc/total_train_step):.4f}')\n",
        "\n",
        "    resnet18.eval() \n",
        "    # Validation\n",
        "    with torch.no_grad():\n",
        "        val_acc = 0\n",
        "        val_loss=0\n",
        "        for i, (images, target) in enumerate(valid_loader, 1):\n",
        "\n",
        "            y_trans = target[0]\n",
        "            y_true = target[1]\n",
        "\n",
        "            # Move tensors to the configured device\n",
        "            images = images.to(device)\n",
        "            y_true = y_true.to(device)\n",
        "            y_trans = y_trans.to(device)\n",
        "\n",
        "            outputs = resnet18(images)\n",
        "            val_loss += criterion(outputs, y_trans)\n",
        "            #val_acc += get_accuracy(outputs, y_true)\n",
        "            val_acc += accuracy(outputs, y_true)\n",
        "\n",
        "    if val_acc/total_val_step > BEST_VAL_METRIC:\n",
        "        BEST_VAL_METRIC = val_acc/total_val_step\n",
        "        BEST_MODEL = resnet18.state_dict() \n",
        "\n",
        "    print(f'Accuracy of the network on the 5000 validation images: {(val_acc/total_val_step):.4f}, loss: {(val_loss/total_val_step):.4f}') "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eStoYUJ2cmCt",
        "outputId": "a5866637-3432-4e7d-91fd-bb4bd587b787",
        "execution": {
          "iopub.status.busy": "2022-09-22T20:16:48.769019Z",
          "iopub.execute_input": "2022-09-22T20:16:48.769496Z",
          "iopub.status.idle": "2022-09-22T21:07:13.079411Z",
          "shell.execute_reply.started": "2022-09-22T20:16:48.769415Z",
          "shell.execute_reply": "2022-09-22T21:07:13.077023Z"
        },
        "trusted": true
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/40] - Loss: 2.0191, Accuracy: 0.2171\n",
            "Accuracy of the network on the 5000 validation images: 0.2533, loss: 2.0108\n",
            "Epoch [2/40] - Loss: 2.0305, Accuracy: 0.2229\n",
            "Accuracy of the network on the 5000 validation images: 0.2552, loss: 2.0249\n",
            "Epoch [3/40] - Loss: 2.0147, Accuracy: 0.2350\n",
            "Accuracy of the network on the 5000 validation images: 0.2723, loss: 1.9962\n",
            "Epoch [4/40] - Loss: 2.0062, Accuracy: 0.2361\n",
            "Accuracy of the network on the 5000 validation images: 0.2795, loss: 1.9866\n",
            "Epoch [5/40] - Loss: 1.9936, Accuracy: 0.2628\n",
            "Accuracy of the network on the 5000 validation images: 0.3036, loss: 1.9776\n",
            "Epoch [6/40] - Loss: 1.9827, Accuracy: 0.2793\n",
            "Accuracy of the network on the 5000 validation images: 0.3209, loss: 1.9573\n",
            "Epoch [7/40] - Loss: 1.9423, Accuracy: 0.3072\n",
            "Accuracy of the network on the 5000 validation images: 0.3494, loss: 1.9215\n",
            "Epoch [8/40] - Loss: 1.9145, Accuracy: 0.3284\n",
            "Accuracy of the network on the 5000 validation images: 0.3780, loss: 1.8980\n",
            "Epoch [9/40] - Loss: 1.8777, Accuracy: 0.3649\n",
            "Accuracy of the network on the 5000 validation images: 0.3962, loss: 1.8659\n",
            "Epoch [10/40] - Loss: 1.8253, Accuracy: 0.3886\n",
            "Accuracy of the network on the 5000 validation images: 0.4230, loss: 1.8117\n",
            "Epoch [11/40] - Loss: 1.7674, Accuracy: 0.4200\n",
            "Accuracy of the network on the 5000 validation images: 0.4496, loss: 1.7569\n",
            "Epoch [12/40] - Loss: 1.7127, Accuracy: 0.4513\n",
            "Accuracy of the network on the 5000 validation images: 0.4781, loss: 1.7223\n",
            "Epoch [13/40] - Loss: 1.6626, Accuracy: 0.4893\n",
            "Accuracy of the network on the 5000 validation images: 0.4998, loss: 1.6737\n",
            "Epoch [14/40] - Loss: 1.6056, Accuracy: 0.5139\n",
            "Accuracy of the network on the 5000 validation images: 0.5195, loss: 1.6303\n",
            "Epoch [15/40] - Loss: 1.5319, Accuracy: 0.5493\n",
            "Accuracy of the network on the 5000 validation images: 0.5511, loss: 1.5692\n",
            "Epoch [16/40] - Loss: 1.4510, Accuracy: 0.5791\n",
            "Accuracy of the network on the 5000 validation images: 0.5804, loss: 1.5098\n",
            "Epoch [17/40] - Loss: 1.3686, Accuracy: 0.6069\n",
            "Accuracy of the network on the 5000 validation images: 0.5846, loss: 1.4568\n",
            "Epoch [18/40] - Loss: 1.2885, Accuracy: 0.6331\n",
            "Accuracy of the network on the 5000 validation images: 0.6000, loss: 1.4230\n",
            "Epoch [19/40] - Loss: 1.2201, Accuracy: 0.6591\n",
            "Accuracy of the network on the 5000 validation images: 0.6203, loss: 1.3778\n",
            "Epoch [20/40] - Loss: 1.1595, Accuracy: 0.6787\n",
            "Accuracy of the network on the 5000 validation images: 0.6369, loss: 1.3596\n",
            "Epoch [21/40] - Loss: 1.0995, Accuracy: 0.6993\n",
            "Accuracy of the network on the 5000 validation images: 0.6402, loss: 1.3437\n",
            "Epoch [22/40] - Loss: 1.0484, Accuracy: 0.7169\n",
            "Accuracy of the network on the 5000 validation images: 0.6440, loss: 1.3329\n",
            "Epoch [23/40] - Loss: 0.9935, Accuracy: 0.7390\n",
            "Accuracy of the network on the 5000 validation images: 0.6565, loss: 1.2959\n",
            "Epoch [24/40] - Loss: 0.9350, Accuracy: 0.7550\n",
            "Accuracy of the network on the 5000 validation images: 0.6649, loss: 1.3043\n",
            "Epoch [25/40] - Loss: 0.8864, Accuracy: 0.7721\n",
            "Accuracy of the network on the 5000 validation images: 0.6765, loss: 1.2880\n",
            "Epoch [26/40] - Loss: 0.8404, Accuracy: 0.7873\n",
            "Accuracy of the network on the 5000 validation images: 0.6830, loss: 1.2860\n",
            "Epoch [27/40] - Loss: 0.8016, Accuracy: 0.8000\n",
            "Accuracy of the network on the 5000 validation images: 0.6859, loss: 1.2712\n",
            "Epoch [28/40] - Loss: 0.7516, Accuracy: 0.8149\n",
            "Accuracy of the network on the 5000 validation images: 0.6867, loss: 1.2799\n",
            "Epoch [29/40] - Loss: 0.7075, Accuracy: 0.8261\n",
            "Accuracy of the network on the 5000 validation images: 0.7024, loss: 1.2358\n",
            "Epoch [30/40] - Loss: 0.6771, Accuracy: 0.8370\n",
            "Accuracy of the network on the 5000 validation images: 0.7037, loss: 1.2685\n",
            "Epoch [31/40] - Loss: 0.6402, Accuracy: 0.8486\n",
            "Accuracy of the network on the 5000 validation images: 0.7045, loss: 1.2606\n",
            "Epoch [32/40] - Loss: 0.5993, Accuracy: 0.8620\n",
            "Accuracy of the network on the 5000 validation images: 0.7076, loss: 1.2837\n",
            "Epoch [33/40] - Loss: 0.5676, Accuracy: 0.8702\n",
            "Accuracy of the network on the 5000 validation images: 0.7036, loss: 1.2927\n",
            "Epoch [34/40] - Loss: 0.5374, Accuracy: 0.8799\n",
            "Accuracy of the network on the 5000 validation images: 0.7070, loss: 1.2953\n",
            "Epoch [35/40] - Loss: 0.5057, Accuracy: 0.8898\n",
            "Accuracy of the network on the 5000 validation images: 0.7120, loss: 1.3051\n",
            "Epoch [36/40] - Loss: 0.4693, Accuracy: 0.8990\n",
            "Accuracy of the network on the 5000 validation images: 0.7209, loss: 1.2940\n",
            "Epoch [37/40] - Loss: 0.4416, Accuracy: 0.9068\n",
            "Accuracy of the network on the 5000 validation images: 0.7115, loss: 1.3168\n",
            "Epoch [38/40] - Loss: 0.4187, Accuracy: 0.9123\n",
            "Accuracy of the network on the 5000 validation images: 0.7127, loss: 1.3369\n",
            "Epoch [39/40] - Loss: 0.4012, Accuracy: 0.9185\n",
            "Accuracy of the network on the 5000 validation images: 0.7156, loss: 1.3784\n",
            "Epoch [40/40] - Loss: 0.3689, Accuracy: 0.9265\n",
            "Accuracy of the network on the 5000 validation images: 0.7177, loss: 1.3431\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing\n",
        "resnet18.load_state_dict(BEST_MODEL)\n",
        "\n",
        "total_test_step=len(test_loader)\n",
        "\n",
        "with torch.no_grad():\n",
        "    test_acc=0\n",
        "    test_loss=0\n",
        "\n",
        "    for i, (images, target) in enumerate(test_loader, 1):\n",
        "        \n",
        "        y_trans = target[0]\n",
        "        y_true = target[1]\n",
        "        \n",
        "        images = images.to(device)\n",
        "        y_true = y_true.to(device)\n",
        "        y_trans = y_trans.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = resnet18(images)\n",
        "        \n",
        "        # Loss\n",
        "        test_loss += criterion(outputs,y_trans)\n",
        "        test_acc += accuracy(outputs, y_true)\n",
        "\n",
        "    print(f'Accuracy of the network on test images: {(test_acc/total_test_step):.4f}, loss: {(test_loss/total_test_step):.4f}')"
      ],
      "metadata": {
        "id": "5Bv9EVemdb8q",
        "execution": {
          "iopub.status.busy": "2022-09-22T21:07:13.081452Z",
          "iopub.execute_input": "2022-09-22T21:07:13.082222Z",
          "iopub.status.idle": "2022-09-22T21:07:17.269852Z",
          "shell.execute_reply.started": "2022-09-22T21:07:13.082172Z",
          "shell.execute_reply": "2022-09-22T21:07:17.268237Z"
        },
        "trusted": true,
        "outputId": "f2421208-061f-4ed5-cc3a-f4f4550c5623",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on test images: 0.7336, loss: 1.2873\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lqw6WDBqczFO"
      },
      "execution_count": 29,
      "outputs": []
    }
  ]
}