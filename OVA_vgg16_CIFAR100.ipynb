{"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","gpuClass":"standard"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip3 install torch_optimizer torchmetrics\n!nvidia-smi","metadata":{"id":"8wS9TMzde74O","colab":{"base_uri":"https://localhost:8080/"},"outputId":"168c9a55-01ab-4329-ba8f-e04e7118564a","execution":{"iopub.status.busy":"2022-09-21T00:24:43.150301Z","iopub.execute_input":"2022-09-21T00:24:43.150955Z","iopub.status.idle":"2022-09-21T00:24:56.041546Z","shell.execute_reply.started":"2022-09-21T00:24:43.150859Z","shell.execute_reply":"2022-09-21T00:24:56.040197Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting torch_optimizer\n  Downloading torch_optimizer-0.3.0-py3-none-any.whl (61 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 kB\u001b[0m \u001b[31m636.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: torchmetrics in /opt/conda/lib/python3.7/site-packages (0.9.3)\nCollecting pytorch-ranger>=0.1.1\n  Downloading pytorch_ranger-0.1.1-py3-none-any.whl (14 kB)\nRequirement already satisfied: torch>=1.5.0 in /opt/conda/lib/python3.7/site-packages (from torch_optimizer) (1.11.0)\nRequirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.7/site-packages (from torchmetrics) (1.21.6)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from torchmetrics) (21.3)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torchmetrics) (4.3.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->torchmetrics) (3.0.9)\nInstalling collected packages: pytorch-ranger, torch_optimizer\nSuccessfully installed pytorch-ranger-0.1.1 torch_optimizer-0.3.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mWed Sep 21 00:24:55 2022       \n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.82.01    Driver Version: 470.82.01    CUDA Version: 11.4     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n| N/A   39C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n                                                                               \n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n|  No running processes found                                                 |\n+-----------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch_optimizer import Ranger\nfrom torchvision import datasets\nfrom torchvision import transforms,models\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.utils.data.dataloader import DataLoader\nfrom torch.utils.data import random_split\nfrom torchmetrics import Accuracy\nfrom torch.optim.lr_scheduler import CyclicLR\n\ntorch.manual_seed(43)","metadata":{"id":"DocA9o6Wal6K","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1a3a2ce0-9802-4f38-d4ec-ffdf15455956","execution":{"iopub.status.busy":"2022-09-21T00:24:56.045506Z","iopub.execute_input":"2022-09-21T00:24:56.046251Z","iopub.status.idle":"2022-09-21T00:24:57.568424Z","shell.execute_reply.started":"2022-09-21T00:24:56.046205Z","shell.execute_reply":"2022-09-21T00:24:57.567432Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7f746c774ab0>"},"metadata":{}}]},{"cell_type":"code","source":"# Device configuration\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"id":"esbUB9VcarSC","execution":{"iopub.status.busy":"2022-09-21T00:24:57.569973Z","iopub.execute_input":"2022-09-21T00:24:57.570693Z","iopub.status.idle":"2022-09-21T00:24:57.648530Z","shell.execute_reply.started":"2022-09-21T00:24:57.570628Z","shell.execute_reply":"2022-09-21T00:24:57.647274Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"\ndef target_trans(target):\n  y = -torch.ones(100)\n  y[target] = 1\n\n  return y,target\n  \n'''\n  global labels\n  label = labels[target]\n  for j in range(27):\n    if label in get_descendants(labels[100+j]):\n      y[100+j] = 1\n'''\n  ","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"CKmlDGbYauBE","outputId":"9d28f1f9-0f30-455e-b246-7b6b38b52fac","execution":{"iopub.status.busy":"2022-09-21T00:24:57.651856Z","iopub.execute_input":"2022-09-21T00:24:57.652231Z","iopub.status.idle":"2022-09-21T00:24:57.661219Z","shell.execute_reply.started":"2022-09-21T00:24:57.652196Z","shell.execute_reply":"2022-09-21T00:24:57.660078Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"'\\n  global labels\\n  label = labels[target]\\n  for j in range(27):\\n    if label in get_descendants(labels[100+j]):\\n      y[100+j] = 1\\n'"},"metadata":{}}]},{"cell_type":"code","source":"transform_train = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomCrop(size=[32,32], padding=4),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\ntransform_test = transforms.Compose([\n    transforms.CenterCrop(size=[32,32]),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\ndataset = datasets.CIFAR100(root='data/', download=True, transform=transform_train,target_transform=target_trans)\ntest_dataset = datasets.CIFAR100(root='data/', train=False, transform=transform_test,target_transform=target_trans)\n\n\nval_size = 5000\ntrain_size = len(dataset) - val_size\ntrain_ds, val_ds = random_split(dataset, [train_size, val_size])\nbatch_size=256\n\ntrain_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4)\nvalid_loader = DataLoader(val_ds, batch_size, num_workers=4)\ntest_loader = DataLoader(test_dataset, batch_size, num_workers=4)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RvWoz_Vsaxv6","outputId":"a1132e7d-bb51-41a3-9a4f-77898ac34945","execution":{"iopub.status.busy":"2022-09-21T00:24:57.662501Z","iopub.execute_input":"2022-09-21T00:24:57.663533Z","iopub.status.idle":"2022-09-21T00:25:05.071883Z","shell.execute_reply.started":"2022-09-21T00:24:57.663498Z","shell.execute_reply":"2022-09-21T00:25:05.070664Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to data/cifar-100-python.tar.gz\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/169001437 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13b212dee5ba4b2b869152bc6fa77f87"}},"metadata":{}},{"name":"stdout","text":"Extracting data/cifar-100-python.tar.gz to data/\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  cpuset_checked))\n","output_type":"stream"}]},{"cell_type":"code","source":"class Hinge_Loss(torch.nn.Module):\n    \n    def __init__(self):\n        super(Hinge_Loss,self).__init__()\n        \n    def forward(self,y_p,y_t):\n\n        temp = 1 - y_p * y_t\n        \n        zero = torch.zeros(y_p.size()[0],y_p.size()[1])\n        zero = zero.cuda()\n        clamp = torch.max(temp,zero)\n    \n        total_loss = torch.sum(clamp)/y_p.size()[0]\n        return total_loss","metadata":{"id":"IARmmjZTbGMx","execution":{"iopub.status.busy":"2022-09-21T00:25:05.073468Z","iopub.execute_input":"2022-09-21T00:25:05.074113Z","iopub.status.idle":"2022-09-21T00:25:05.081317Z","shell.execute_reply.started":"2022-09-21T00:25:05.074074Z","shell.execute_reply":"2022-09-21T00:25:05.080240Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"num_classes = 100\nnum_epochs = 100\n","metadata":{"id":"ZQc7HygQeCUT","execution":{"iopub.status.busy":"2022-09-21T00:25:05.082933Z","iopub.execute_input":"2022-09-21T00:25:05.083340Z","iopub.status.idle":"2022-09-21T00:25:05.107558Z","shell.execute_reply.started":"2022-09-21T00:25:05.083296Z","shell.execute_reply":"2022-09-21T00:25:05.106699Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class VGGForCiFar100(nn.Module):\n  def __init__(self, hid_dim=5000, dropout=0.5, n_classes=100, use_fc=True, freeze=False):\n    super().__init__()\n    self.vgg = models.vgg16(pretrained=True)\n    if not use_fc:\n      self.vgg.classifier = nn.Linear(512 * 7 * 7, n_classes)\n    else:\n      self.vgg.classifier = nn.Sequential(\n              nn.Linear(512 * 7 * 7, 4096),\n              nn.ReLU(True),\n              nn.Dropout(p=dropout),\n              nn.Linear(4096, 4096),\n              nn.ReLU(True),\n              nn.Dropout(p=dropout),\n              nn.Linear(4096, n_classes),\n          )\n      \n    if freeze:\n      for param in self.vgg.features.parameters():\n        param.requires_grad = False\n      for param in self.vgg.avg_pool.parameters():\n        param.requires_grad = False\n      for param in self.vgg.flatten.parameters():\n        param.requires_grad = False\n    \n\n  def forward(self, x):\n    return F.log_softmax(self.vgg(x), dim=-1)","metadata":{"id":"OLP6Q6yxauMw","execution":{"iopub.status.busy":"2022-09-21T00:25:05.109072Z","iopub.execute_input":"2022-09-21T00:25:05.109839Z","iopub.status.idle":"2022-09-21T00:25:05.119998Z","shell.execute_reply.started":"2022-09-21T00:25:05.109781Z","shell.execute_reply":"2022-09-21T00:25:05.119025Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"\nmodel = VGGForCiFar100(n_classes=num_classes).to(device)\ncriterion = Hinge_Loss().to(device)\naccuracy = Accuracy(num_classes=num_classes).to(device)\noptimizer = Ranger(model.parameters(), lr=1e-3, weight_decay=1e-4) \nscheduler = CyclicLR(optimizer, base_lr=1e-6, max_lr=1e-3, step_size_up=len(train_loader)//2, cycle_momentum=False)\n","metadata":{"id":"0c42xudTbEsB","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6827f613-4f71-428c-e673-bcada3ee6030","execution":{"iopub.status.busy":"2022-09-21T00:25:05.121449Z","iopub.execute_input":"2022-09-21T00:25:05.122105Z","iopub.status.idle":"2022-09-21T00:25:22.157560Z","shell.execute_reply.started":"2022-09-21T00:25:05.122068Z","shell.execute_reply":"2022-09-21T00:25:22.156509Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/528M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1900269a02b444da9a02c0941c6d7fb2"}},"metadata":{}}]},{"cell_type":"code","source":"model","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"etxLVu_JauWo","outputId":"f7147aa0-5626-4c22-9f07-b173ef58fc63","execution":{"iopub.status.busy":"2022-09-21T00:25:22.161194Z","iopub.execute_input":"2022-09-21T00:25:22.161615Z","iopub.status.idle":"2022-09-21T00:25:22.169806Z","shell.execute_reply.started":"2022-09-21T00:25:22.161574Z","shell.execute_reply":"2022-09-21T00:25:22.168696Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"VGGForCiFar100(\n  (vgg): VGG(\n    (features): Sequential(\n      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): ReLU(inplace=True)\n      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (3): ReLU(inplace=True)\n      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (6): ReLU(inplace=True)\n      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (8): ReLU(inplace=True)\n      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (11): ReLU(inplace=True)\n      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (13): ReLU(inplace=True)\n      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (15): ReLU(inplace=True)\n      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (18): ReLU(inplace=True)\n      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (20): ReLU(inplace=True)\n      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (22): ReLU(inplace=True)\n      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (25): ReLU(inplace=True)\n      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (27): ReLU(inplace=True)\n      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (29): ReLU(inplace=True)\n      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    )\n    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n    (classifier): Sequential(\n      (0): Linear(in_features=25088, out_features=4096, bias=True)\n      (1): ReLU(inplace=True)\n      (2): Dropout(p=0.5, inplace=False)\n      (3): Linear(in_features=4096, out_features=4096, bias=True)\n      (4): ReLU(inplace=True)\n      (5): Dropout(p=0.5, inplace=False)\n      (6): Linear(in_features=4096, out_features=100, bias=True)\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"\ndef get_accuracy(output, target):\n\n  batch_size = target.size(0)\n  correct=0\n\n  pred = output.max(dim=1)[1]\n\n  correct = pred==target\n\n  acc = correct.float().sum(0)\n\n  return acc/batch_size\n","metadata":{"id":"_XEwQBgWcMYQ","execution":{"iopub.status.busy":"2022-09-21T00:25:22.171295Z","iopub.execute_input":"2022-09-21T00:25:22.172042Z","iopub.status.idle":"2022-09-21T00:25:22.178694Z","shell.execute_reply.started":"2022-09-21T00:25:22.172006Z","shell.execute_reply":"2022-09-21T00:25:22.177713Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"total_train_step = len(train_loader)\n#print(total_train_step)\ntotal_val_step=len(valid_loader)\nBEST_VAL_METRIC = 0\nBEST_MODEL = None\n\nfor epoch in range(1, num_epochs+1):\n\n    train_loss=0\n    train_acc=0.0\n    model.train()\n\n    for i, (images, target) in enumerate(train_loader, 1):\n\n        y_trans = target[0]\n        y_true = target[1]\n\n        # Move tensors to the configured device\n        images = images.to(device)\n        y_true = y_true.to(device)\n        y_trans = y_trans.to(device)\n        \n        # Forward pass\n        outputs = model(images)\n        loss = criterion(outputs, y_trans)\n\n        train_loss += loss\n        #train_acc += get_accuracy(outputs, y_true)\n        train_acc += accuracy(outputs, y_true)\n        \n        \n        # Backward and optimize\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n        optimizer.zero_grad()\n\n    print(f'Epoch [{epoch}/{num_epochs}] - Loss: {(train_loss/total_train_step):.4f}, Accuracy: {(train_acc/total_train_step):.4f}')\n\n    model.eval() \n    # Validation\n    with torch.no_grad():\n        val_acc = 0\n        val_loss=0\n        for i, (images, target) in enumerate(valid_loader, 1):\n\n            y_trans = target[0]\n            y_true = target[1]\n\n            # Move tensors to the configured device\n            images = images.to(device)\n            y_true = y_true.to(device)\n            y_trans = y_trans.to(device)\n\n            outputs = model(images)\n            val_loss += criterion(outputs, y_trans)\n            #val_acc += get_accuracy(outputs, y_true)\n            val_acc += accuracy(outputs, y_true)\n\n    if val_acc/total_val_step > BEST_VAL_METRIC:\n        BEST_VAL_METRIC = val_acc/total_val_step\n        BEST_MODEL = model.state_dict() \n\n    print(f'Accuracy of the network on the 5000 validation images: {(val_acc/total_val_step):.4f}, loss: {(val_loss/total_val_step):.4f}') ","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eStoYUJ2cmCt","outputId":"6025dae7-b145-4f47-eca0-be1814137a41","execution":{"iopub.status.busy":"2022-09-21T00:25:22.180385Z","iopub.execute_input":"2022-09-21T00:25:22.181110Z","iopub.status.idle":"2022-09-21T01:12:33.852777Z","shell.execute_reply.started":"2022-09-21T00:25:22.181074Z","shell.execute_reply":"2022-09-21T01:12:33.851606Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/pytorch_ranger/ranger.py:172: UserWarning: This overload of addcmul_ is deprecated:\n\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\nConsider using one of the following signatures instead:\n\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at  /usr/local/src/pytorch/torch/csrc/utils/python_arg_parser.cpp:1055.)\n  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/100] - Loss: 4.0942, Accuracy: 0.2603\nAccuracy of the network on the 5000 validation images: 0.4612, loss: 3.0160\nEpoch [2/100] - Loss: 3.0833, Accuracy: 0.4529\nAccuracy of the network on the 5000 validation images: 0.5186, loss: 2.7556\nEpoch [3/100] - Loss: 2.7946, Accuracy: 0.5261\nAccuracy of the network on the 5000 validation images: 0.5631, loss: 2.6524\nEpoch [4/100] - Loss: 2.6180, Accuracy: 0.5733\nAccuracy of the network on the 5000 validation images: 0.5817, loss: 2.5943\nEpoch [5/100] - Loss: 2.5020, Accuracy: 0.6024\nAccuracy of the network on the 5000 validation images: 0.5957, loss: 2.5241\nEpoch [6/100] - Loss: 2.4065, Accuracy: 0.6272\nAccuracy of the network on the 5000 validation images: 0.6046, loss: 2.5068\nEpoch [7/100] - Loss: 2.3066, Accuracy: 0.6534\nAccuracy of the network on the 5000 validation images: 0.6176, loss: 2.4844\nEpoch [8/100] - Loss: 2.2184, Accuracy: 0.6758\nAccuracy of the network on the 5000 validation images: 0.6206, loss: 2.4596\nEpoch [9/100] - Loss: 2.1581, Accuracy: 0.6915\nAccuracy of the network on the 5000 validation images: 0.6277, loss: 2.4530\nEpoch [10/100] - Loss: 2.1148, Accuracy: 0.7059\nAccuracy of the network on the 5000 validation images: 0.6331, loss: 2.4539\nEpoch [11/100] - Loss: 2.0522, Accuracy: 0.7214\nAccuracy of the network on the 5000 validation images: 0.6395, loss: 2.4534\nEpoch [12/100] - Loss: 2.0048, Accuracy: 0.7334\nAccuracy of the network on the 5000 validation images: 0.6343, loss: 2.4799\nEpoch [13/100] - Loss: 1.9619, Accuracy: 0.7475\nAccuracy of the network on the 5000 validation images: 0.6354, loss: 2.4747\nEpoch [14/100] - Loss: 1.9414, Accuracy: 0.7537\nAccuracy of the network on the 5000 validation images: 0.6361, loss: 2.4869\nEpoch [15/100] - Loss: 1.9049, Accuracy: 0.7640\nAccuracy of the network on the 5000 validation images: 0.6478, loss: 2.4733\nEpoch [16/100] - Loss: 1.8774, Accuracy: 0.7715\nAccuracy of the network on the 5000 validation images: 0.6375, loss: 2.5175\nEpoch [17/100] - Loss: 1.8735, Accuracy: 0.7725\nAccuracy of the network on the 5000 validation images: 0.6515, loss: 2.4745\nEpoch [18/100] - Loss: 1.8239, Accuracy: 0.7852\nAccuracy of the network on the 5000 validation images: 0.6504, loss: 2.5104\nEpoch [19/100] - Loss: 1.7846, Accuracy: 0.7974\nAccuracy of the network on the 5000 validation images: 0.6461, loss: 2.4995\nEpoch [20/100] - Loss: 1.7828, Accuracy: 0.7954\nAccuracy of the network on the 5000 validation images: 0.6463, loss: 2.5184\nEpoch [21/100] - Loss: 1.7322, Accuracy: 0.8117\nAccuracy of the network on the 5000 validation images: 0.6523, loss: 2.4992\nEpoch [22/100] - Loss: 1.7348, Accuracy: 0.8112\nAccuracy of the network on the 5000 validation images: 0.6474, loss: 2.5547\nEpoch [23/100] - Loss: 1.7126, Accuracy: 0.8172\nAccuracy of the network on the 5000 validation images: 0.6585, loss: 2.5409\nEpoch [24/100] - Loss: 1.6979, Accuracy: 0.8227\nAccuracy of the network on the 5000 validation images: 0.6519, loss: 2.5517\nEpoch [25/100] - Loss: 1.6644, Accuracy: 0.8292\nAccuracy of the network on the 5000 validation images: 0.6489, loss: 2.5709\nEpoch [26/100] - Loss: 1.6378, Accuracy: 0.8382\nAccuracy of the network on the 5000 validation images: 0.6486, loss: 2.5844\nEpoch [27/100] - Loss: 1.6292, Accuracy: 0.8390\nAccuracy of the network on the 5000 validation images: 0.6412, loss: 2.6156\nEpoch [28/100] - Loss: 1.6362, Accuracy: 0.8395\nAccuracy of the network on the 5000 validation images: 0.6412, loss: 2.6355\nEpoch [29/100] - Loss: 1.6260, Accuracy: 0.8418\nAccuracy of the network on the 5000 validation images: 0.6496, loss: 2.6180\nEpoch [30/100] - Loss: 1.6022, Accuracy: 0.8486\nAccuracy of the network on the 5000 validation images: 0.6513, loss: 2.5935\nEpoch [31/100] - Loss: 1.5955, Accuracy: 0.8511\nAccuracy of the network on the 5000 validation images: 0.6535, loss: 2.6125\nEpoch [32/100] - Loss: 1.5705, Accuracy: 0.8545\nAccuracy of the network on the 5000 validation images: 0.6555, loss: 2.6431\nEpoch [33/100] - Loss: 1.5707, Accuracy: 0.8576\nAccuracy of the network on the 5000 validation images: 0.6545, loss: 2.6678\nEpoch [34/100] - Loss: 1.5389, Accuracy: 0.8650\nAccuracy of the network on the 5000 validation images: 0.6480, loss: 2.6959\nEpoch [35/100] - Loss: 1.5222, Accuracy: 0.8694\nAccuracy of the network on the 5000 validation images: 0.6544, loss: 2.6698\nEpoch [36/100] - Loss: 1.5311, Accuracy: 0.8705\nAccuracy of the network on the 5000 validation images: 0.6512, loss: 2.7032\nEpoch [37/100] - Loss: 1.5297, Accuracy: 0.8696\nAccuracy of the network on the 5000 validation images: 0.6645, loss: 2.6188\nEpoch [38/100] - Loss: 1.5083, Accuracy: 0.8746\nAccuracy of the network on the 5000 validation images: 0.6523, loss: 2.6525\nEpoch [39/100] - Loss: 1.4986, Accuracy: 0.8770\nAccuracy of the network on the 5000 validation images: 0.6567, loss: 2.6793\nEpoch [40/100] - Loss: 1.5016, Accuracy: 0.8793\nAccuracy of the network on the 5000 validation images: 0.6467, loss: 2.7728\nEpoch [41/100] - Loss: 1.4938, Accuracy: 0.8787\nAccuracy of the network on the 5000 validation images: 0.6486, loss: 2.7248\nEpoch [42/100] - Loss: 1.4742, Accuracy: 0.8851\nAccuracy of the network on the 5000 validation images: 0.6521, loss: 2.7587\nEpoch [43/100] - Loss: 1.4742, Accuracy: 0.8842\nAccuracy of the network on the 5000 validation images: 0.6504, loss: 2.7082\nEpoch [44/100] - Loss: 1.4772, Accuracy: 0.8851\nAccuracy of the network on the 5000 validation images: 0.6548, loss: 2.7092\nEpoch [45/100] - Loss: 1.4504, Accuracy: 0.8911\nAccuracy of the network on the 5000 validation images: 0.6572, loss: 2.7302\nEpoch [46/100] - Loss: 1.4575, Accuracy: 0.8908\nAccuracy of the network on the 5000 validation images: 0.6503, loss: 2.7046\nEpoch [47/100] - Loss: 1.4376, Accuracy: 0.8941\nAccuracy of the network on the 5000 validation images: 0.6549, loss: 2.7674\nEpoch [48/100] - Loss: 1.4394, Accuracy: 0.8948\nAccuracy of the network on the 5000 validation images: 0.6560, loss: 2.7103\nEpoch [49/100] - Loss: 1.4366, Accuracy: 0.8957\nAccuracy of the network on the 5000 validation images: 0.6498, loss: 2.8120\nEpoch [50/100] - Loss: 1.4331, Accuracy: 0.8949\nAccuracy of the network on the 5000 validation images: 0.6494, loss: 2.7624\nEpoch [51/100] - Loss: 1.4191, Accuracy: 0.8999\nAccuracy of the network on the 5000 validation images: 0.6501, loss: 2.7569\nEpoch [52/100] - Loss: 1.4201, Accuracy: 0.9000\nAccuracy of the network on the 5000 validation images: 0.6602, loss: 2.7223\nEpoch [53/100] - Loss: 1.4145, Accuracy: 0.9011\nAccuracy of the network on the 5000 validation images: 0.6526, loss: 2.7570\nEpoch [54/100] - Loss: 1.4064, Accuracy: 0.9034\nAccuracy of the network on the 5000 validation images: 0.6533, loss: 2.8243\nEpoch [55/100] - Loss: 1.3974, Accuracy: 0.9059\nAccuracy of the network on the 5000 validation images: 0.6553, loss: 2.8241\nEpoch [56/100] - Loss: 1.3911, Accuracy: 0.9072\nAccuracy of the network on the 5000 validation images: 0.6530, loss: 2.8436\nEpoch [57/100] - Loss: 1.4055, Accuracy: 0.9043\nAccuracy of the network on the 5000 validation images: 0.6457, loss: 2.7933\nEpoch [58/100] - Loss: 1.3953, Accuracy: 0.9081\nAccuracy of the network on the 5000 validation images: 0.6535, loss: 2.8741\nEpoch [59/100] - Loss: 1.3842, Accuracy: 0.9104\nAccuracy of the network on the 5000 validation images: 0.6480, loss: 2.8044\nEpoch [60/100] - Loss: 1.4005, Accuracy: 0.9087\nAccuracy of the network on the 5000 validation images: 0.6456, loss: 2.8559\nEpoch [61/100] - Loss: 1.3822, Accuracy: 0.9102\nAccuracy of the network on the 5000 validation images: 0.6464, loss: 2.8516\nEpoch [62/100] - Loss: 1.3800, Accuracy: 0.9121\nAccuracy of the network on the 5000 validation images: 0.6490, loss: 2.8479\nEpoch [63/100] - Loss: 1.3759, Accuracy: 0.9120\nAccuracy of the network on the 5000 validation images: 0.6455, loss: 2.8539\nEpoch [64/100] - Loss: 1.3467, Accuracy: 0.9182\nAccuracy of the network on the 5000 validation images: 0.6517, loss: 2.8663\nEpoch [65/100] - Loss: 1.3551, Accuracy: 0.9181\nAccuracy of the network on the 5000 validation images: 0.6481, loss: 2.8649\nEpoch [66/100] - Loss: 1.3659, Accuracy: 0.9167\nAccuracy of the network on the 5000 validation images: 0.6496, loss: 2.8233\nEpoch [67/100] - Loss: 1.3591, Accuracy: 0.9173\nAccuracy of the network on the 5000 validation images: 0.6500, loss: 2.8737\nEpoch [68/100] - Loss: 1.3512, Accuracy: 0.9186\nAccuracy of the network on the 5000 validation images: 0.6486, loss: 2.8855\nEpoch [69/100] - Loss: 1.3584, Accuracy: 0.9180\nAccuracy of the network on the 5000 validation images: 0.6446, loss: 2.8940\nEpoch [70/100] - Loss: 1.3516, Accuracy: 0.9194\nAccuracy of the network on the 5000 validation images: 0.6462, loss: 2.8930\nEpoch [71/100] - Loss: 1.3426, Accuracy: 0.9226\nAccuracy of the network on the 5000 validation images: 0.6551, loss: 2.8179\nEpoch [72/100] - Loss: 1.3567, Accuracy: 0.9196\nAccuracy of the network on the 5000 validation images: 0.6446, loss: 2.8459\nEpoch [73/100] - Loss: 1.3381, Accuracy: 0.9232\nAccuracy of the network on the 5000 validation images: 0.6537, loss: 2.8289\nEpoch [74/100] - Loss: 1.3295, Accuracy: 0.9247\nAccuracy of the network on the 5000 validation images: 0.6531, loss: 2.8724\nEpoch [75/100] - Loss: 1.3438, Accuracy: 0.9229\nAccuracy of the network on the 5000 validation images: 0.6401, loss: 2.9552\nEpoch [76/100] - Loss: 1.3410, Accuracy: 0.9229\nAccuracy of the network on the 5000 validation images: 0.6392, loss: 2.9138\nEpoch [77/100] - Loss: 1.3279, Accuracy: 0.9265\nAccuracy of the network on the 5000 validation images: 0.6467, loss: 2.9680\nEpoch [78/100] - Loss: 1.3301, Accuracy: 0.9253\nAccuracy of the network on the 5000 validation images: 0.6422, loss: 2.9209\nEpoch [79/100] - Loss: 1.3285, Accuracy: 0.9259\nAccuracy of the network on the 5000 validation images: 0.6433, loss: 2.9345\nEpoch [80/100] - Loss: 1.3303, Accuracy: 0.9268\nAccuracy of the network on the 5000 validation images: 0.6467, loss: 2.8959\nEpoch [81/100] - Loss: 1.3439, Accuracy: 0.9221\nAccuracy of the network on the 5000 validation images: 0.6426, loss: 2.9416\nEpoch [82/100] - Loss: 1.3240, Accuracy: 0.9291\nAccuracy of the network on the 5000 validation images: 0.6466, loss: 2.8842\nEpoch [83/100] - Loss: 1.3343, Accuracy: 0.9258\nAccuracy of the network on the 5000 validation images: 0.6440, loss: 2.8860\nEpoch [84/100] - Loss: 1.3068, Accuracy: 0.9305\nAccuracy of the network on the 5000 validation images: 0.6364, loss: 2.9516\nEpoch [85/100] - Loss: 1.3208, Accuracy: 0.9300\nAccuracy of the network on the 5000 validation images: 0.6471, loss: 2.9010\nEpoch [86/100] - Loss: 1.3158, Accuracy: 0.9286\nAccuracy of the network on the 5000 validation images: 0.6490, loss: 2.8805\nEpoch [87/100] - Loss: 1.3340, Accuracy: 0.9262\nAccuracy of the network on the 5000 validation images: 0.6440, loss: 2.9328\nEpoch [88/100] - Loss: 1.3349, Accuracy: 0.9262\nAccuracy of the network on the 5000 validation images: 0.6415, loss: 2.9501\nEpoch [89/100] - Loss: 1.3117, Accuracy: 0.9302\nAccuracy of the network on the 5000 validation images: 0.6471, loss: 2.9599\nEpoch [90/100] - Loss: 1.3272, Accuracy: 0.9274\nAccuracy of the network on the 5000 validation images: 0.6444, loss: 2.9174\nEpoch [91/100] - Loss: 1.3272, Accuracy: 0.9284\nAccuracy of the network on the 5000 validation images: 0.6453, loss: 2.9273\nEpoch [92/100] - Loss: 1.3156, Accuracy: 0.9305\nAccuracy of the network on the 5000 validation images: 0.6448, loss: 2.9223\nEpoch [93/100] - Loss: 1.3084, Accuracy: 0.9320\nAccuracy of the network on the 5000 validation images: 0.6558, loss: 2.8950\nEpoch [94/100] - Loss: 1.3204, Accuracy: 0.9290\nAccuracy of the network on the 5000 validation images: 0.6495, loss: 2.9418\nEpoch [95/100] - Loss: 1.3307, Accuracy: 0.9276\nAccuracy of the network on the 5000 validation images: 0.6387, loss: 3.0414\nEpoch [96/100] - Loss: 1.3082, Accuracy: 0.9324\nAccuracy of the network on the 5000 validation images: 0.6406, loss: 2.9500\nEpoch [97/100] - Loss: 1.3284, Accuracy: 0.9297\nAccuracy of the network on the 5000 validation images: 0.6411, loss: 2.9338\nEpoch [98/100] - Loss: 1.3256, Accuracy: 0.9301\nAccuracy of the network on the 5000 validation images: 0.6433, loss: 2.9842\nEpoch [99/100] - Loss: 1.3172, Accuracy: 0.9305\nAccuracy of the network on the 5000 validation images: 0.6419, loss: 2.9532\nEpoch [100/100] - Loss: 1.3010, Accuracy: 0.9330\nAccuracy of the network on the 5000 validation images: 0.6549, loss: 2.9400\n","output_type":"stream"}]},{"cell_type":"code","source":"#Testing\nmodel.load_state_dict(BEST_MODEL)\n\ntotal_test_step=len(test_loader)\n\nwith torch.no_grad():\n    test_acc=0\n    test_loss=0\n\n    for i, (images, target) in enumerate(test_loader, 1):\n        \n        y_trans = target[0]\n        y_true = target[1]\n        \n        images = images.to(device)\n        y_true = y_true.to(device)\n        y_trans = y_trans.to(device)\n\n        # Forward pass\n        outputs = model(images)\n        \n        # Loss\n        test_loss += criterion(outputs,y_trans)\n        test_acc += accuracy(outputs, y_true)\n\n    print(f'Accuracy of the network on test images: {(test_acc/total_test_step):.4f}, loss: {(test_loss/total_test_step):.4f}')","metadata":{"id":"5Bv9EVemdb8q","execution":{"iopub.status.busy":"2022-09-21T01:12:33.857194Z","iopub.execute_input":"2022-09-21T01:12:33.858909Z","iopub.status.idle":"2022-09-21T01:12:37.792588Z","shell.execute_reply.started":"2022-09-21T01:12:33.858866Z","shell.execute_reply":"2022-09-21T01:12:37.791362Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Accuracy of the network on test images: 0.6615, loss: 2.9168\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"id":"Lqw6WDBqczFO"},"execution_count":null,"outputs":[]}]}