{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3306c71b8db04333ab0b617c34390e3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_10bf72a5d5e84e1da6cdd49fa059df17",
              "IPY_MODEL_fdf69b74ccc7403299a3662163f42fec",
              "IPY_MODEL_6ce422e47cba4c0391faff9bb5b0d183"
            ],
            "layout": "IPY_MODEL_3f0370d4b313429ba5718fd063c29d95"
          }
        },
        "10bf72a5d5e84e1da6cdd49fa059df17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3771266964a54d038f84b9322f35ae4c",
            "placeholder": "​",
            "style": "IPY_MODEL_8493da8a4ffb452fa4c961578d0605a0",
            "value": "100%"
          }
        },
        "fdf69b74ccc7403299a3662163f42fec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc84f850721e4a1782979024e4c00168",
            "max": 169001437,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_efc9486fe0f74ccf90211a2484ef01ad",
            "value": 169001437
          }
        },
        "6ce422e47cba4c0391faff9bb5b0d183": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d41ad73f252c4514b9aaaff5e3c3746d",
            "placeholder": "​",
            "style": "IPY_MODEL_07c4952e9cea497abe81a225a91f0882",
            "value": " 169001437/169001437 [00:02&lt;00:00, 70323917.24it/s]"
          }
        },
        "3f0370d4b313429ba5718fd063c29d95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3771266964a54d038f84b9322f35ae4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8493da8a4ffb452fa4c961578d0605a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc84f850721e4a1782979024e4c00168": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efc9486fe0f74ccf90211a2484ef01ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d41ad73f252c4514b9aaaff5e3c3746d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07c4952e9cea497abe81a225a91f0882": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8ed97694e3d443a9ecd7bc82f610cd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c3545ac148fe40d79e89b3e8ec030bbe",
              "IPY_MODEL_9b21fd9e362e4f108f9699010d40a872",
              "IPY_MODEL_e4fd2db31f2d4b1091378504c78c6f2c"
            ],
            "layout": "IPY_MODEL_15e2359406544bb382b838261def44d8"
          }
        },
        "c3545ac148fe40d79e89b3e8ec030bbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e82547175b39477abacffe7f36cb9b96",
            "placeholder": "​",
            "style": "IPY_MODEL_fe350440f8e84dc7b73c6937d5faf4f3",
            "value": "100%"
          }
        },
        "9b21fd9e362e4f108f9699010d40a872": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e38f556e21fe43e0a07f13e6ab78af07",
            "max": 553433881,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a896d6dde06249f4b140207145c4cfed",
            "value": 553433881
          }
        },
        "e4fd2db31f2d4b1091378504c78c6f2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de98fa10efbd487ea445357be74b98b7",
            "placeholder": "​",
            "style": "IPY_MODEL_f340fe38083f4af48873f8a3a4cc59c6",
            "value": " 528M/528M [00:05&lt;00:00, 158MB/s]"
          }
        },
        "15e2359406544bb382b838261def44d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e82547175b39477abacffe7f36cb9b96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe350440f8e84dc7b73c6937d5faf4f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e38f556e21fe43e0a07f13e6ab78af07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a896d6dde06249f4b140207145c4cfed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de98fa10efbd487ea445357be74b98b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f340fe38083f4af48873f8a3a4cc59c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torch_optimizer torchmetrics\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "uo6ktQJuCy9a",
        "execution": {
          "iopub.status.busy": "2022-09-22T11:44:00.995194Z",
          "iopub.execute_input": "2022-09-22T11:44:00.996055Z",
          "iopub.status.idle": "2022-09-22T11:44:11.989875Z",
          "shell.execute_reply.started": "2022-09-22T11:44:00.995991Z",
          "shell.execute_reply": "2022-09-22T11:44:11.988711Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2511ab14-d345-4c1e-f88b-81b3836c14e1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch_optimizer\n",
            "  Downloading torch_optimizer-0.3.0-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 491 kB/s \n",
            "\u001b[?25hCollecting torchmetrics\n",
            "  Downloading torchmetrics-0.9.3-py3-none-any.whl (419 kB)\n",
            "\u001b[K     |████████████████████████████████| 419 kB 10.8 MB/s \n",
            "\u001b[?25hCollecting pytorch-ranger>=0.1.1\n",
            "  Downloading pytorch_ranger-0.1.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from torch_optimizer) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.5.0->torch_optimizer) (4.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.9)\n",
            "Installing collected packages: pytorch-ranger, torchmetrics, torch-optimizer\n",
            "Successfully installed pytorch-ranger-0.1.1 torch-optimizer-0.3.0 torchmetrics-0.9.3\n",
            "Thu Sep 22 18:28:54 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   56C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import sys\n",
        "import torch.nn.functional as F\n",
        "from torch_optimizer import Ranger\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms,models\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "from torchmetrics import Accuracy\n",
        "from torch.optim.lr_scheduler import CyclicLR\n",
        "\n",
        "torch.manual_seed(43)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-22T11:44:11.992770Z",
          "iopub.execute_input": "2022-09-22T11:44:11.993214Z",
          "iopub.status.idle": "2022-09-22T11:44:12.003379Z",
          "shell.execute_reply.started": "2022-09-22T11:44:11.993167Z",
          "shell.execute_reply": "2022-09-22T11:44:12.002225Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOPALF9ZGcX9",
        "outputId": "562f9c31-2fcc-469a-ea4e-130df72c4849"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f01b9c476f0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "id": "XgUAGcwJC6JY",
        "outputId": "f90ca20c-bffe-4b75-ba82-69f9f9298a06",
        "execution": {
          "iopub.status.busy": "2022-09-22T11:44:12.005385Z",
          "iopub.execute_input": "2022-09-22T11:44:12.005829Z",
          "iopub.status.idle": "2022-09-22T11:44:12.017283Z",
          "shell.execute_reply.started": "2022-09-22T11:44:12.005710Z",
          "shell.execute_reply": "2022-09-22T11:44:12.015947Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tree Hierarchy of the labels\n",
        "\n",
        "Tree = {\"entity\" : [\"nature\", \"manmade\"] , \"nature\":[\"flora\", \"bigAnimals\", \"smallAnimals\", \"aquaticAnimals\", \"scenes\"], \"manmade\" : [\"householdElectrical\", \"householdFurniture\", \"foodContainers\", \"vehicles1\",\"vehicles2\",\"largeManmadeOutdoorThings\"],\n",
        "        \"flora\": [\"fruitsAndVegetables\",\"flowers\",\"trees\"],\"bigAnimals\": [\"largeCarnivores\", \"largeOmniAndHerbivores\", \"people\", \"mediumSizedMammals\"],\"smallAnimals\":[\"smallMammals\", \"reptiles\", \"insects\", \"nonInsectInvertebrates\"], \"aquaticAnimals\":[\"aquaticMammals\", \"fish\"],\"scenes\":[\"cloud\",\"forest\",\"mountain\",\"plain\",\"sea\"],\n",
        "        \"householdElectrical\":[\"clock\", \"keyboard\", \"lamp\", \"telephone\", \"television\"], \"householdFurniture\":[\"bed\", \"chair\", \"couch\", \"table\", \"wardrobe\"],\"foodContainers\":[\"bottle\", \"bowl\", \"can\", \"cup\", \"plate\"], \"vehicles1\":[\"bicycle\", \"bus\", \"motorcycle\", \"pickup_truck\", \"train\"],\"vehicles2\":[\"lawn_mower\", \"rocket\", \"streetcar\", \"tank\", \"tractor\"],\"largeManmadeOutdoorThings\":[\"bridge\", \"castle\", \"house\", \"road\", \"skyscraper\"],\n",
        "        \"flowers\":[\"orchid\", \"poppy\", \"rose\", \"sunflower\", \"tulip\"],\"fruitsAndVegetables\":[\"apple\", \"mushroom\", \"orange\", \"pear\", \"sweet_pepper\"],\"trees\":[\"maple_tree\", \"oak_tree\", \"palm_tree\", \"pine_tree\", \"willow_tree\"],\"largeCarnivores\":[\"bear\", \"leopard\", \"lion\", \"tiger\", \"wolf\"],\"largeOmniAndHerbivores\":[\"camel\", \"cattle\", \"chimpanzee\", \"elephant\", \"kangaroo\"],\"people\":[\"baby\", \"boy\", \"girl\", \"man\", \"woman\"],\n",
        "        \"mediumSizedMammals\":[\"fox\", \"porcupine\", \"possum\", \"raccoon\", \"skunk\"],\"smallMammals\":[\"hamster\", \"mouse\", \"rabbit\", \"shrew\", \"squirrel\"],\"reptiles\":[\"crocodile\", \"dinosaur\", \"lizard\", \"snake\", \"turtle\"],\"insects\":[\"bee\", \"beetle\", \"butterfly\", \"caterpillar\", \"cockroach\"],\"nonInsectInvertebrates\":[\"crab\", \"lobster\", \"snail\", \"spider\", \"worm\"],\"aquaticMammals\":[\"beaver\", \"dolphin\", \"otter\", \"seal\", \"whale\"],\n",
        "        \"fish\":[\"aquarium_fish\", \"flatfish\", \"ray\", \"shark\", \"trout\"]}\n",
        "\n",
        "labels = [\"apple\",\"aquarium_fish\",\"baby\",\"bear\",\"beaver\",\"bed\",\"bee\",\"beetle\",\"bicycle\",\"bottle\",\"bowl\",\"boy\",\"bridge\",\"bus\",\"butterfly\",\"camel\",\"can\",\"castle\",\"caterpillar\",\"cattle\",\"chair\",\"chimpanzee\",\"clock\",\"cloud\",\"cockroach\",\"couch\",\"crab\",\"crocodile\",\"cup\",\"dinosaur\",\"dolphin\",\"elephant\",\"flatfish\",\"forest\",\"fox\",\"girl\",\"hamster\",\"house\",\"kangaroo\",\"keyboard\",\"lamp\",\"lawn_mower\",\"leopard\",\"lion\",\"lizard\",\"lobster\",\"man\",\"maple_tree\",\"motorcycle\",\"mountain\",\"mouse\",\"mushroom\",\"oak_tree\",\"orange\",\"orchid\",\"otter\",\"palm_tree\",\"pear\",\"pickup_truck\",\"pine_tree\",\"plain\",\"plate\",\"poppy\",\"porcupine\",\"possum\",\"rabbit\",\"raccoon\",\"ray\",\"road\",\"rocket\",\"rose\",\"sea\",\"seal\",\"shark\",\"shrew\",\"skunk\",\"skyscraper\",\"snail\",\"snake\",\"spider\",\"squirrel\",\"streetcar\",\"sunflower\",\"sweet_pepper\",\"table\",\"tank\",\"telephone\",\"television\",\"tiger\",\"tractor\",\"train\",\"trout\",\"tulip\",\"turtle\",\"wardrobe\",\"whale\",\"willow_tree\",\"wolf\",\"woman\",\"worm\", \"flowers\",\"fruitsAndVegetables\", \"trees\", \"largeCarnivores\", \"largeOmniAndHerbivores\", \"people\", \"mediumSizedMammals\", \"smallMammals\", \"reptiles\", \"insects\", \"nonInsectInvertebrates\", \"aquaticMammals\", \"fish\", \"flora\", \"bigAnimals\", \"smallAnimals\",\"aquaticAnimals\", \"scenes\", \"householdElectrical\", \"householdFurniture\", \"foodContainers\", \"vehicles1\", \"vehicles2\", \"largeManmadeOutdoorThings\", \"nature\" ,\"manmade\", \"entity\"]\n"
      ],
      "metadata": {
        "id": "1ZWEkJ2ADbbl",
        "execution": {
          "iopub.status.busy": "2022-09-22T11:44:12.020752Z",
          "iopub.execute_input": "2022-09-22T11:44:12.021191Z",
          "iopub.status.idle": "2022-09-22T11:44:12.036888Z",
          "shell.execute_reply.started": "2022-09-22T11:44:12.021149Z",
          "shell.execute_reply": "2022-09-22T11:44:12.035579Z"
        },
        "trusted": true
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Level-wise representation of labels\n",
        "\n",
        "level = [None]*5\n",
        "\n",
        "level[0] = [\"entity\"]\n",
        "level[1] = [\"nature\", \"manmade\"]\n",
        "level[2] = [\"flora\", \"bigAnimals\", \"smallAnimals\", \"aquaticAnimals\", \"scenes\", \"householdElectrical\", \"householdFurniture\",\"foodContainers\", \"vehicles1\", \"vehicles2\",\"largeManmadeOutdoorThings\"]\n",
        "level[3] = [\"flowers\", \"fruitsAndVegetables\", \"trees\", \"largeCarnivores\", \"largeOmniAndHerbivores\", \"people\", \"mediumSizedMammals\", \"smallMammals\", \"reptiles\", \"insects\", \"nonInsectInvertebrates\", \"aquaticMammals\", \"fish\", \"cloud\", \"forest\", \"mountain\", \"plain\", \"sea\", \"clock\", \"keyboard\", \"lamp\", \"telephone\", \"television\", \"bed\", \"chair\", \"couch\", \"table\", \"wardrobe\", \"bottle\", \"bowl\", \"can\", \"cup\", \"plate\", \"bicycle\", \"bus\", \"motorcycle\", \"pickup_truck\", \"train\", \"lawn_mower\", \"rocket\", \"streetcar\", \"tank\", \"tractor\", \"bridge\", \"castle\", \"house\", \"road\", \"skyscraper\"]\n",
        "level[4] = [\"orchid\", \"poppy\", \"rose\", \"sunflower\", \"tulip\", \"apple\", \"mushroom\", \"orange\", \"pear\", \"sweet_pepper\", \"maple_tree\", \"oak_tree\", \"palm_tree\", \"pine_tree\", \"willow_tree\", \"bear\", \"leopard\", \"lion\", \"tiger\", \"wolf\", \"camel\", \"cattle\", \"chimpanzee\", \"elephant\", \"kangaroo\", \"baby\", \"boy\", \"girl\", \"man\", \"woman\", \"fox\", \"porcupine\", \"possum\", \"raccoon\", \"skunk\", \"hamster\", \"mouse\", \"rabbit\", \"shrew\", \"squirrel\", \"crocodile\", \"dinosaur\", \"lizard\", \"snake\", \"turtle\", \"bee\", \"beetle\", \"butterfly\", \"caterpillar\", \"cockroach\", \"crab\", \"lobster\", \"snail\", \"spider\", \"worm\", \"beaver\", \"dolphin\", \"otter\", \"seal\", \"whale\", \"aquarium_fish\", \"flatfish\", \"ray\", \"shark\", \"trout\"]\n",
        "\n",
        "\n",
        "nodesAtLevel = []*5\n",
        "nodesAtLevel.append(1)\n",
        "nodesAtLevel.append(2)\n",
        "nodesAtLevel.append(11)\n",
        "nodesAtLevel.append(48)\n",
        "nodesAtLevel.append(65)\n",
        "\n",
        "logNodesAtLevel = []*5\n",
        "logNodesAtLevel.append(1)\n",
        "logNodesAtLevel.append(1)\n",
        "logNodesAtLevel.append(4)\n",
        "logNodesAtLevel.append(6)\n",
        "logNodesAtLevel.append(7)\n"
      ],
      "metadata": {
        "id": "YCUB1YHuDio_",
        "execution": {
          "iopub.status.busy": "2022-09-22T11:44:12.038418Z",
          "iopub.execute_input": "2022-09-22T11:44:12.038801Z",
          "iopub.status.idle": "2022-09-22T11:44:12.052732Z",
          "shell.execute_reply.started": "2022-09-22T11:44:12.038765Z",
          "shell.execute_reply": "2022-09-22T11:44:12.051799Z"
        },
        "trusted": true
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input    - class label of the CIFAR100 dataset\n",
        "# Function - To find the level of the given class label\n",
        "# output   - Returns an integer which represents the level of the class label and returns -1 if it doesn't belong to any level\n",
        "def get_level(node):\n",
        "  if (node in level[0]):\n",
        "    return 0\n",
        "  elif (node in level[1]):\n",
        "    return 1\n",
        "  elif (node in level[2]):\n",
        "    return 2\n",
        "  elif (node in level[3]):\n",
        "    return 3\n",
        "  elif (node in level[4]):\n",
        "    return 4\n",
        "  else:\n",
        "    return -1\n",
        "\n",
        "# Input    - class label of the CIFAR100 dataset\n",
        "# Function - To find all the children of the given class label using the Tree hierarchy\n",
        "# output   - Returns an list of the labels which are children and returns None if the given label is a leaf\n",
        "def get_children(node):\n",
        "  if node in Tree.keys():\n",
        "    return Tree[node]    \n",
        "  else:\n",
        "    return None\n",
        "\n",
        "# Input    - class label of the CIFAR100 dataset\n",
        "# Function - To find the parent of the given class label using the level and children function.\n",
        "# output   - Returns the parent of the class label\n",
        "def get_parent(node):\n",
        "  l = get_level(node)\n",
        "  if l == 0: \n",
        "    return node\n",
        "  for i in level[l-1]:\n",
        "    if(get_children(i) is not None):\n",
        "      if node in get_children(i):\n",
        "        return i\n",
        "  return None\n",
        "\n",
        "# Input    - class label of the CIFAR100 dataset and the level of the label\n",
        "# Function - finds ancestors of the the given label. \n",
        "# output   - Returns the label itself if given level is greater than the label's level else returns the ancestor at level l\n",
        "def get_ancestor(node, l):\n",
        "  h = get_level(node)\n",
        "  if l >= h:\n",
        "    return node\n",
        "  y = node\n",
        "  for i in range(h-l):\n",
        "    y = get_parent(y)\n",
        "  return y\n",
        "\n",
        "# Input    - class label of the CIFAR100 dataset\n",
        "# Function - To find the descendants of the given class label including the given class label\n",
        "# output   - Returns an list of class labels which are descendants else empty list if the class label is a leaf.\n",
        "def get_descendants(node):\n",
        "  c = get_children(node)\n",
        "  d = []\n",
        "  if c is not None:\n",
        "    for i in c:\n",
        "      d.extend(get_descendants(i)) \n",
        "    return d\n",
        "  else :\n",
        "    return [node] \n",
        "\n",
        "\n",
        "# Input    - two class labels of the CIFAR100 dataset\n",
        "# Function - Finds the distance between the given two nodes\n",
        "# output   - Returns an integer which represents the distance between class labels\n",
        "def tree_loss(node1,node2):\n",
        "  l1 = get_level(node1)\n",
        "  l2 = get_level(node2)\n",
        "  l = min(l1,l2)\n",
        "  while l >= 0:\n",
        "    if get_ancestor(node1,l) == get_ancestor(node2,l):\n",
        "      break\n",
        "    else :\n",
        "      l = l-1\n",
        "  return l1 + l2 - 2*l\n"
      ],
      "metadata": {
        "id": "hyt9gDUnDi7c",
        "execution": {
          "iopub.status.busy": "2022-09-22T11:44:12.054567Z",
          "iopub.execute_input": "2022-09-22T11:44:12.055009Z",
          "iopub.status.idle": "2022-09-22T11:44:12.069900Z",
          "shell.execute_reply.started": "2022-09-22T11:44:12.054969Z",
          "shell.execute_reply": "2022-09-22T11:44:12.068852Z"
        },
        "trusted": true
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tLoss(output,target,tau_values=[0.5,0.5,0.5,0.5,0.5]):\n",
        "  batch_size = target.size(0)\n",
        "  num_classes = output.size(1)\n",
        "  h = 4\n",
        "  val = None\n",
        "  pred = None\n",
        "  loss = 0\n",
        "  global labels\n",
        "  global level\n",
        "  l1 = logNodesAtLevel[0]\n",
        "  l2 = logNodesAtLevel[1] + l1\n",
        "  l3 = logNodesAtLevel[2] + l2\n",
        "  l4 = logNodesAtLevel[3] + l3\n",
        "  l5 = logNodesAtLevel[4] + l4\n",
        "\n",
        "  # Loop for each example in the batch\n",
        "  for i in range(batch_size):\n",
        "    # t is the actual target of the ith example in the batch\n",
        "    t = target[i]\n",
        "    # Go searching bottom-up in the hierarchy tree\n",
        "    h = 4\n",
        "    while h >= 0:\n",
        "      \n",
        "      # At each level in the bottom-up traversal, we take the minimum of the outputs of nodes \n",
        "      # Based on the height consider the range in the totat set of output nodes of the model\n",
        "      # Get the min value of the absolute values\n",
        "      # If the min val isgreater than the threshold at that level the we break and get class index at level from \n",
        "      # the signs of those outputs are defined in btoi function\n",
        "      values = output.clone().detach()\n",
        "      if h == 4:        \n",
        "        values = values[i,l4:l5]        \n",
        "        val,_ = torch.min(torch.abs(values),0)   \n",
        "        if val >= tau_values[4]:\n",
        "          pred = b2i(values,h)\n",
        "          pred_label = labels[pred]\n",
        "          break\n",
        "\n",
        "      if h == 3:\n",
        "        values = values[i,l3:l4]\n",
        "        val,_ = torch.min(torch.abs(values),0)        \n",
        "        if val >= tau_values[3]:\n",
        "          pred = b2i(values,h)\n",
        "          pred_label = level[h][pred]\n",
        "          break\n",
        "\n",
        "      if h == 2:\n",
        "        values = values[i,l2:l3]\n",
        "        val,_ = torch.min(torch.abs(values),0)        \n",
        "        if val >= tau_values[2]:\n",
        "          pred = b2i(values,h)\n",
        "          pred_label = level[h][pred]\n",
        "          break\n",
        "\n",
        "      if h == 1:\n",
        "        values = values[i,l1:l2]\n",
        "        val,_ = torch.min(torch.abs(values),0)        \n",
        "        if val >= tau_values[1]:\n",
        "          pred = b2i(values,h)\n",
        "          pred_label = level[h][pred]\n",
        "          break\n",
        "\n",
        "      if h == 0:\n",
        "        values = values[i,0:l1]\n",
        "        val,_ = torch.min(torch.abs(values),0)        \n",
        "        if val >= tau_values[0]:\n",
        "          pred = b2i(values,h)\n",
        "          pred_label = level[h][pred]\n",
        "          break \n",
        "          \n",
        "      h = h - 1\n",
        "\n",
        "    # tree_loss() function gives the tree distance between the two nodes\n",
        "    # Total loss for the batch is calculated\n",
        "    loss = loss + tree_loss(labels[t],pred_label)\n",
        "\n",
        "  loss = loss/batch_size\n",
        "\n",
        "  # Average loss for the batch is returned\n",
        "  return loss"
      ],
      "metadata": {
        "id": "ZnZ8kL4kD5Dd",
        "execution": {
          "iopub.status.busy": "2022-09-22T11:44:12.071420Z",
          "iopub.execute_input": "2022-09-22T11:44:12.071928Z",
          "iopub.status.idle": "2022-09-22T11:44:12.087910Z",
          "shell.execute_reply.started": "2022-09-22T11:44:12.071889Z",
          "shell.execute_reply": "2022-09-22T11:44:12.086902Z"
        },
        "trusted": true
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to convert integer to binary\n",
        "def itob(target,bits):\n",
        "  encoding=-np.ones(bits)\n",
        "  ''' -1 in place of 0 in binary representation of a number'''\n",
        "  j = bits-1\n",
        "  while(target!=0):\n",
        "    if (target%2)==1 :\n",
        "      encoding[j] = 1\n",
        "    target = target//2\n",
        "    j = j-1\n",
        "  return encoding"
      ],
      "metadata": {
        "id": "W_YKRITDD8F1",
        "execution": {
          "iopub.status.busy": "2022-09-22T11:44:12.089514Z",
          "iopub.execute_input": "2022-09-22T11:44:12.089926Z",
          "iopub.status.idle": "2022-09-22T11:44:12.101332Z",
          "shell.execute_reply.started": "2022-09-22T11:44:12.089890Z",
          "shell.execute_reply": "2022-09-22T11:44:12.100363Z"
        },
        "trusted": true
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function to convert a batch of binary numbers into integer\n",
        "def btoi(binary,h):\n",
        "  # this is to convert a -1 and 1 to 0 and 1 respectively\n",
        "  batch_size = binary.size(0)\n",
        "  binary = -torch.sign(binary)\n",
        "  bits = logNodesAtLevel[h]\n",
        "  binary = (binary+1)/2\n",
        "  #binary = torch.ceil(binary)\n",
        "\n",
        "  j = bits-1\n",
        "  nodes = [1,2,11,48,100]\n",
        "  #j = bits-1 \n",
        "  decoded_target = torch.zeros(batch_size).to(device)\n",
        "  while j>=0:\n",
        "    decoded_target = decoded_target + binary[:,j] * (2**(bits-j-1))\n",
        "    j = j-1\n",
        "  \n",
        "  return decoded_target\n",
        "\n",
        "#function to convert a single binary number into integer\n",
        "def b2i(binary,h):\n",
        "  batch_size = binary.size(0)\n",
        "  binary = -torch.sign(binary)\n",
        "  bits = logNodesAtLevel[h]\n",
        "  binary = (binary+1)/2\n",
        "  #binary = torch.ceil(binary)\n",
        "  #print(binary.shape)\n",
        "  j = bits-1\n",
        "  nodes = [1,2,11,48,100]\n",
        "\n",
        "  max_label = nodes[h]\n",
        "  decoded_target = 0\n",
        "  while j>=0:\n",
        "    decoded_target = decoded_target + binary[j] * (2**(bits-j-1))\n",
        "    j = j-1\n",
        "  if decoded_target >= max_label:\n",
        "    decoded_target = decoded_target - 2**(bits-1)\n",
        "  return decoded_target.type(torch.LongTensor)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-22T11:44:12.102690Z",
          "iopub.execute_input": "2022-09-22T11:44:12.103125Z",
          "iopub.status.idle": "2022-09-22T11:44:12.114411Z",
          "shell.execute_reply.started": "2022-09-22T11:44:12.103085Z",
          "shell.execute_reply": "2022-09-22T11:44:12.113513Z"
        },
        "trusted": true,
        "id": "NslbgxzSGcYA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def target_translate(target):\n",
        "    #print(target)\n",
        "    global labels\n",
        "    global level\n",
        "    global logNodesAtLevel\n",
        "    \n",
        "    translated_target = []  # target is translated into 19 bits (1+1+4+6+7)\n",
        "    # 5 is the height of the tree\n",
        "    target_label = labels[target]\n",
        "    for i in range(4):\n",
        "      ancestor = get_ancestor(target_label,i)\n",
        "      #print(ancestor)\n",
        "      if ancestor==target_label and (ancestor not in level[i]):\n",
        "        print(ancestor)\n",
        "        translated_target.extend(itob(nodesAtLevel[i]+1,logNodesAtLevel[i]))\n",
        "      else:\n",
        "        translated_target.extend(itob(level[i].index(ancestor),logNodesAtLevel[i]))\n",
        "        \n",
        "    translated_target.extend(itob(target,logNodesAtLevel[4]))\n",
        "    translated_target = torch.FloatTensor(translated_target)\n",
        "\n",
        "    return target, translated_target"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-22T11:44:12.119277Z",
          "iopub.execute_input": "2022-09-22T11:44:12.119543Z",
          "iopub.status.idle": "2022-09-22T11:44:12.127831Z",
          "shell.execute_reply.started": "2022-09-22T11:44:12.119512Z",
          "shell.execute_reply": "2022-09-22T11:44:12.126845Z"
        },
        "trusted": true,
        "id": "mjhch0ApGcYB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(size=[32,32], padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.CenterCrop(size=[32,32]),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "dataset = datasets.CIFAR100(root='data/', train=True, download=True, transform=transform_train,target_transform=target_translate)\n",
        "test_dataset = datasets.CIFAR100(root='data/', train=False, download=True, transform=transform_test,target_transform=target_translate)\n",
        "\n",
        "\n",
        "val_size = 5000\n",
        "train_size = len(dataset) - val_size\n",
        "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
        "batch_size=256\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4)\n",
        "valid_loader = DataLoader(val_ds, batch_size, num_workers=4)\n",
        "test_loader = DataLoader(test_dataset, batch_size, num_workers=4)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-22T11:44:12.129237Z",
          "iopub.execute_input": "2022-09-22T11:44:12.129773Z",
          "iopub.status.idle": "2022-09-22T11:44:13.965034Z",
          "shell.execute_reply.started": "2022-09-22T11:44:12.129739Z",
          "shell.execute_reply": "2022-09-22T11:44:13.964042Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "3306c71b8db04333ab0b617c34390e3e",
            "10bf72a5d5e84e1da6cdd49fa059df17",
            "fdf69b74ccc7403299a3662163f42fec",
            "6ce422e47cba4c0391faff9bb5b0d183",
            "3f0370d4b313429ba5718fd063c29d95",
            "3771266964a54d038f84b9322f35ae4c",
            "8493da8a4ffb452fa4c961578d0605a0",
            "dc84f850721e4a1782979024e4c00168",
            "efc9486fe0f74ccf90211a2484ef01ad",
            "d41ad73f252c4514b9aaaff5e3c3746d",
            "07c4952e9cea497abe81a225a91f0882"
          ]
        },
        "id": "SCNDpeAGGcYB",
        "outputId": "5d407672-e466-4a26-a913-6b1b6e841cc8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/169001437 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3306c71b8db04333ab0b617c34390e3e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/cifar-100-python.tar.gz to data/\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 19\n",
        "num_epochs = 100"
      ],
      "metadata": {
        "id": "CQcVrz_VFj2d",
        "execution": {
          "iopub.status.busy": "2022-09-22T11:44:13.966400Z",
          "iopub.execute_input": "2022-09-22T11:44:13.967105Z",
          "iopub.status.idle": "2022-09-22T11:44:13.973109Z",
          "shell.execute_reply.started": "2022-09-22T11:44:13.967069Z",
          "shell.execute_reply": "2022-09-22T11:44:13.970830Z"
        },
        "trusted": true
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BEP_Loss(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "        super(BEP_Loss,self).__init__()\n",
        "        \n",
        "  def forward(self,y_p,y_t):\n",
        "    \n",
        "    batch_size = y_p.size(0)  # shape of y_p is batch_size * 19\n",
        "\n",
        "    z = y_p*y_t              # shape of z is batch_size * 19\n",
        "\n",
        "    start = 0   \n",
        "    loss = 0 \n",
        "    zeros = torch.zeros(batch_size).to(device) #shape of zeros is batch_size\n",
        "    \n",
        "    for i in range(5):\n",
        "      t1 = z[:,start:start+logNodesAtLevel[i]]\n",
        "      w,_ = torch.max(t1,1)\n",
        "      w1 = torch.max(w+1,zeros)\n",
        "      loss = loss + torch.sum(w1)\n",
        "      start = start+logNodesAtLevel[i]\n",
        "\n",
        "    loss = loss/batch_size\n",
        "    return loss"
      ],
      "metadata": {
        "id": "r_N8KAr1GOPg",
        "execution": {
          "iopub.status.busy": "2022-09-22T11:44:13.974486Z",
          "iopub.execute_input": "2022-09-22T11:44:13.975336Z",
          "iopub.status.idle": "2022-09-22T11:44:13.984354Z",
          "shell.execute_reply.started": "2022-09-22T11:44:13.975298Z",
          "shell.execute_reply": "2022-09-22T11:44:13.983362Z"
        },
        "trusted": true
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VGGForCiFar100(nn.Module):\n",
        "  def __init__(self, hid_dim=5000, dropout=0.5, n_classes=100, use_fc=True, freeze=False):\n",
        "    super().__init__()\n",
        "    self.vgg = models.vgg16(pretrained=True)\n",
        "    if not use_fc:\n",
        "      self.vgg.classifier = nn.Linear(512 * 7 * 7, n_classes)\n",
        "    else:\n",
        "      self.vgg.classifier = nn.Sequential(\n",
        "              nn.Linear(512 * 7 * 7, 5000),\n",
        "              nn.ReLU(True),\n",
        "              nn.Dropout(p=dropout),\n",
        "              #nn.Linear(4096, 4096),\n",
        "              #nn.ReLU(True),\n",
        "              #nn.Dropout(p=dropout),\n",
        "              nn.Linear(5000, n_classes),\n",
        "          )\n",
        "      \n",
        "    if freeze:\n",
        "      for param in self.vgg.features.parameters():\n",
        "        param.requires_grad = False\n",
        "      for param in self.vgg.avg_pool.parameters():\n",
        "        param.requires_grad = False\n",
        "      for param in self.vgg.flatten.parameters():\n",
        "        param.requires_grad = False\n",
        "    \n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.vgg(x)"
      ],
      "metadata": {
        "id": "d076aP16Fj_T",
        "execution": {
          "iopub.status.busy": "2022-09-22T11:44:13.985797Z",
          "iopub.execute_input": "2022-09-22T11:44:13.986219Z",
          "iopub.status.idle": "2022-09-22T11:44:13.996743Z",
          "shell.execute_reply.started": "2022-09-22T11:44:13.986175Z",
          "shell.execute_reply": "2022-09-22T11:44:13.995570Z"
        },
        "trusted": true
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VGGForCiFar100(n_classes=19).to(device)\n",
        "criterion = BEP_Loss().to(device)\n",
        "accuracy = Accuracy(num_classes=num_classes).to(device)\n",
        "optimizer = Ranger(model.parameters(), lr=1e-3, weight_decay=1e-4) \n",
        "scheduler = CyclicLR(optimizer, base_lr=1e-6, max_lr=1e-3, step_size_up=len(train_loader)//2, cycle_momentum=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-22T12:05:09.793855Z",
          "iopub.execute_input": "2022-09-22T12:05:09.794256Z",
          "iopub.status.idle": "2022-09-22T12:05:12.812737Z",
          "shell.execute_reply.started": "2022-09-22T12:05:09.794217Z",
          "shell.execute_reply": "2022-09-22T12:05:12.811758Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "f8ed97694e3d443a9ecd7bc82f610cd7",
            "c3545ac148fe40d79e89b3e8ec030bbe",
            "9b21fd9e362e4f108f9699010d40a872",
            "e4fd2db31f2d4b1091378504c78c6f2c",
            "15e2359406544bb382b838261def44d8",
            "e82547175b39477abacffe7f36cb9b96",
            "fe350440f8e84dc7b73c6937d5faf4f3",
            "e38f556e21fe43e0a07f13e6ab78af07",
            "a896d6dde06249f4b140207145c4cfed",
            "de98fa10efbd487ea445357be74b98b7",
            "f340fe38083f4af48873f8a3a4cc59c6"
          ]
        },
        "id": "lJWBUioIGcYC",
        "outputId": "9568016b-c85c-486a-f00e-adadd4267ef0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/528M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f8ed97694e3d443a9ecd7bc82f610cd7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "1gHQQmSqGYuT",
        "execution": {
          "iopub.status.busy": "2022-09-22T12:05:17.417642Z",
          "iopub.execute_input": "2022-09-22T12:05:17.418111Z",
          "iopub.status.idle": "2022-09-22T12:05:17.429523Z",
          "shell.execute_reply.started": "2022-09-22T12:05:17.418071Z",
          "shell.execute_reply": "2022-09-22T12:05:17.428478Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eef61a08-1567-4b9a-dbee-fb6892978232"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGGForCiFar100(\n",
              "  (vgg): VGG(\n",
              "    (features): Sequential(\n",
              "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (6): ReLU(inplace=True)\n",
              "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (8): ReLU(inplace=True)\n",
              "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (11): ReLU(inplace=True)\n",
              "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (13): ReLU(inplace=True)\n",
              "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (15): ReLU(inplace=True)\n",
              "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (18): ReLU(inplace=True)\n",
              "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (20): ReLU(inplace=True)\n",
              "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (22): ReLU(inplace=True)\n",
              "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (25): ReLU(inplace=True)\n",
              "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (27): ReLU(inplace=True)\n",
              "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (29): ReLU(inplace=True)\n",
              "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "    (classifier): Sequential(\n",
              "      (0): Linear(in_features=25088, out_features=5000, bias=True)\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Dropout(p=0.5, inplace=False)\n",
              "      (3): Linear(in_features=5000, out_features=19, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy(output, target):\n",
        "\n",
        "  batch_size = target.size(0)\n",
        "  \n",
        "  #checking the values of logm labels\n",
        "  pred=btoi(output[:,12:19],4)\n",
        "\n",
        "  correct = pred==target\n",
        "\n",
        "  return correct.float().sum()/batch_size"
      ],
      "metadata": {
        "id": "-70pu4nzGs9Y",
        "execution": {
          "iopub.status.busy": "2022-09-22T12:05:22.164996Z",
          "iopub.execute_input": "2022-09-22T12:05:22.165381Z",
          "iopub.status.idle": "2022-09-22T12:05:22.170533Z",
          "shell.execute_reply.started": "2022-09-22T12:05:22.165351Z",
          "shell.execute_reply": "2022-09-22T12:05:22.169612Z"
        },
        "trusted": true
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training\n",
        "\n",
        "total_train_step = len(train_loader)\n",
        "total_val_step=len(valid_loader)\n",
        "\n",
        "BEST_VAL_METRIC = 0\n",
        "BEST_MODEL = None\n",
        "\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "\n",
        "    train_loss=0\n",
        "    train_acc=0.0\n",
        "    model.train()\n",
        "\n",
        "    for i, (images, target) in enumerate(train_loader, 1):\n",
        "        \n",
        "        y_true = target[0]\n",
        "        y_trans = target[1]\n",
        "\n",
        "        # Move tensors to the configured device\n",
        "        images = images.to(device)\n",
        "        y_true = y_true.to(device)\n",
        "        y_trans = y_trans.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, y_trans)\n",
        "\n",
        "        train_loss += loss\n",
        "        train_acc += get_accuracy(outputs,y_true)\n",
        "        #train_acc += accuracy(btoi(outputs[:,12:19],4), y_true)\n",
        "        \n",
        "        \n",
        "        # Backward and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "      \n",
        "    print(f'Epoch [{epoch}/{num_epochs}] - Loss: {(train_loss/total_train_step):.4f}, Accuracy: {(train_acc/total_train_step):.4f}')\n",
        "    \n",
        "    # Validation\n",
        "    \n",
        "    model.eval() \n",
        "    \n",
        "    with torch.no_grad():\n",
        "        val_acc = 0\n",
        "        val_loss=0\n",
        "        Tree_Loss_Value = 0\n",
        "        for i, (images, target) in enumerate(valid_loader, 1):\n",
        "\n",
        "            y_true = target[0]\n",
        "            y_trans = target[1]\n",
        "\n",
        "            # Move tensors to the configured device\n",
        "            images = images.to(device)\n",
        "            y_true = y_true.to(device)\n",
        "            y_trans = y_trans.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            val_loss += criterion(outputs, y_trans)\n",
        "            Tree_Loss_Value += tLoss(outputs,y_true)\n",
        "            val_acc += get_accuracy(outputs,y_true)\n",
        "            #val_acc += accuracy(btoi(outputs[:,12:19],4), y_true)\n",
        "\n",
        "    if val_acc/total_val_step > BEST_VAL_METRIC:\n",
        "        BEST_VAL_METRIC = val_acc/total_val_step\n",
        "        BEST_MODEL = model.state_dict() \n",
        "\n",
        "    print(f'Accuracy of the network on validation images: {(val_acc/total_val_step):.4f}, loss: {(val_loss/total_val_step):.4f}, Tree loss: {(Tree_Loss_Value/total_val_step):.4f}') \n"
      ],
      "metadata": {
        "id": "TV6rcoBlHDfA",
        "execution": {
          "iopub.status.busy": "2022-09-22T12:05:27.140401Z",
          "iopub.execute_input": "2022-09-22T12:05:27.140787Z",
          "iopub.status.idle": "2022-09-22T12:05:28.686588Z",
          "shell.execute_reply.started": "2022-09-22T12:05:27.140753Z",
          "shell.execute_reply": "2022-09-22T12:05:28.685012Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e27253b8-a382-48c8-e746-3238dc4afdac"
      },
      "execution_count": 19,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_ranger/ranger.py:172: UserWarning: This overload of addcmul_ is deprecated:\n",
            "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
            "Consider using one of the following signatures instead:\n",
            "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1174.)\n",
            "  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100] - Loss: 3.5567, Accuracy: 0.0198\n",
            "Accuracy of the network on validation images: 0.0870, loss: 2.9421, Tree loss: 2.5257\n",
            "Epoch [2/100] - Loss: 2.8603, Accuracy: 0.0684\n",
            "Accuracy of the network on validation images: 0.1814, loss: 2.6003, Tree loss: 2.1850\n",
            "Epoch [3/100] - Loss: 2.5697, Accuracy: 0.1565\n",
            "Accuracy of the network on validation images: 0.2548, loss: 2.3538, Tree loss: 1.9624\n",
            "Epoch [4/100] - Loss: 2.3216, Accuracy: 0.2274\n",
            "Accuracy of the network on validation images: 0.2934, loss: 2.2122, Tree loss: 1.8581\n",
            "Epoch [5/100] - Loss: 2.1812, Accuracy: 0.2651\n",
            "Accuracy of the network on validation images: 0.3325, loss: 2.1543, Tree loss: 1.8087\n",
            "Epoch [6/100] - Loss: 2.0551, Accuracy: 0.2990\n",
            "Accuracy of the network on validation images: 0.3628, loss: 2.0690, Tree loss: 1.7367\n",
            "Epoch [7/100] - Loss: 1.9621, Accuracy: 0.3388\n",
            "Accuracy of the network on validation images: 0.3939, loss: 2.0026, Tree loss: 1.6627\n",
            "Epoch [8/100] - Loss: 1.8801, Accuracy: 0.3754\n",
            "Accuracy of the network on validation images: 0.4145, loss: 1.9527, Tree loss: 1.6156\n",
            "Epoch [9/100] - Loss: 1.8166, Accuracy: 0.4039\n",
            "Accuracy of the network on validation images: 0.4388, loss: 1.9199, Tree loss: 1.6040\n",
            "Epoch [10/100] - Loss: 1.7241, Accuracy: 0.4342\n",
            "Accuracy of the network on validation images: 0.4548, loss: 1.8943, Tree loss: 1.5688\n",
            "Epoch [11/100] - Loss: 1.6683, Accuracy: 0.4514\n",
            "Accuracy of the network on validation images: 0.4608, loss: 1.8879, Tree loss: 1.5409\n",
            "Epoch [12/100] - Loss: 1.5891, Accuracy: 0.4677\n",
            "Accuracy of the network on validation images: 0.4765, loss: 1.8095, Tree loss: 1.4889\n",
            "Epoch [13/100] - Loss: 1.5365, Accuracy: 0.4831\n",
            "Accuracy of the network on validation images: 0.4687, loss: 1.8174, Tree loss: 1.4835\n",
            "Epoch [14/100] - Loss: 1.4986, Accuracy: 0.4916\n",
            "Accuracy of the network on validation images: 0.4908, loss: 1.7593, Tree loss: 1.4382\n",
            "Epoch [15/100] - Loss: 1.4402, Accuracy: 0.5085\n",
            "Accuracy of the network on validation images: 0.4900, loss: 1.7943, Tree loss: 1.4638\n",
            "Epoch [16/100] - Loss: 1.4136, Accuracy: 0.5187\n",
            "Accuracy of the network on validation images: 0.5050, loss: 1.7549, Tree loss: 1.4201\n",
            "Epoch [17/100] - Loss: 1.3462, Accuracy: 0.5402\n",
            "Accuracy of the network on validation images: 0.5128, loss: 1.7380, Tree loss: 1.4048\n",
            "Epoch [18/100] - Loss: 1.3158, Accuracy: 0.5471\n",
            "Accuracy of the network on validation images: 0.5108, loss: 1.7484, Tree loss: 1.4153\n",
            "Epoch [19/100] - Loss: 1.2721, Accuracy: 0.5613\n",
            "Accuracy of the network on validation images: 0.5274, loss: 1.7107, Tree loss: 1.3768\n",
            "Epoch [20/100] - Loss: 1.2409, Accuracy: 0.5743\n",
            "Accuracy of the network on validation images: 0.5310, loss: 1.7030, Tree loss: 1.3766\n",
            "Epoch [21/100] - Loss: 1.2336, Accuracy: 0.5748\n",
            "Accuracy of the network on validation images: 0.5313, loss: 1.6865, Tree loss: 1.3661\n",
            "Epoch [22/100] - Loss: 1.1769, Accuracy: 0.5891\n",
            "Accuracy of the network on validation images: 0.5287, loss: 1.7043, Tree loss: 1.3571\n",
            "Epoch [23/100] - Loss: 1.1632, Accuracy: 0.5945\n",
            "Accuracy of the network on validation images: 0.5414, loss: 1.6994, Tree loss: 1.3413\n",
            "Epoch [24/100] - Loss: 1.1606, Accuracy: 0.5998\n",
            "Accuracy of the network on validation images: 0.5305, loss: 1.7297, Tree loss: 1.3856\n",
            "Epoch [25/100] - Loss: 1.1303, Accuracy: 0.6066\n",
            "Accuracy of the network on validation images: 0.5509, loss: 1.7016, Tree loss: 1.3572\n",
            "Epoch [26/100] - Loss: 1.0917, Accuracy: 0.6184\n",
            "Accuracy of the network on validation images: 0.5467, loss: 1.6817, Tree loss: 1.3381\n",
            "Epoch [27/100] - Loss: 1.0564, Accuracy: 0.6292\n",
            "Accuracy of the network on validation images: 0.5510, loss: 1.6717, Tree loss: 1.3237\n",
            "Epoch [28/100] - Loss: 1.0434, Accuracy: 0.6368\n",
            "Accuracy of the network on validation images: 0.5512, loss: 1.7068, Tree loss: 1.3335\n",
            "Epoch [29/100] - Loss: 1.0266, Accuracy: 0.6403\n",
            "Accuracy of the network on validation images: 0.5583, loss: 1.7152, Tree loss: 1.3543\n",
            "Epoch [30/100] - Loss: 0.9958, Accuracy: 0.6502\n",
            "Accuracy of the network on validation images: 0.5495, loss: 1.7501, Tree loss: 1.3486\n",
            "Epoch [31/100] - Loss: 0.9843, Accuracy: 0.6597\n",
            "Accuracy of the network on validation images: 0.5656, loss: 1.6765, Tree loss: 1.3243\n",
            "Epoch [32/100] - Loss: 0.9744, Accuracy: 0.6640\n",
            "Accuracy of the network on validation images: 0.5694, loss: 1.7080, Tree loss: 1.3204\n",
            "Epoch [33/100] - Loss: 0.9707, Accuracy: 0.6665\n",
            "Accuracy of the network on validation images: 0.5689, loss: 1.7069, Tree loss: 1.3184\n",
            "Epoch [34/100] - Loss: 0.9551, Accuracy: 0.6748\n",
            "Accuracy of the network on validation images: 0.5722, loss: 1.6886, Tree loss: 1.3176\n",
            "Epoch [35/100] - Loss: 0.9375, Accuracy: 0.6800\n",
            "Accuracy of the network on validation images: 0.5770, loss: 1.6831, Tree loss: 1.3051\n",
            "Epoch [36/100] - Loss: 0.9119, Accuracy: 0.6892\n",
            "Accuracy of the network on validation images: 0.5721, loss: 1.7428, Tree loss: 1.3369\n",
            "Epoch [37/100] - Loss: 0.8880, Accuracy: 0.6949\n",
            "Accuracy of the network on validation images: 0.5716, loss: 1.6534, Tree loss: 1.3046\n",
            "Epoch [38/100] - Loss: 0.8786, Accuracy: 0.6990\n",
            "Accuracy of the network on validation images: 0.5806, loss: 1.6918, Tree loss: 1.2977\n",
            "Epoch [39/100] - Loss: 0.8385, Accuracy: 0.7104\n",
            "Accuracy of the network on validation images: 0.5875, loss: 1.6963, Tree loss: 1.3050\n",
            "Epoch [40/100] - Loss: 0.8387, Accuracy: 0.7128\n",
            "Accuracy of the network on validation images: 0.5868, loss: 1.6999, Tree loss: 1.3060\n",
            "Epoch [41/100] - Loss: 0.8394, Accuracy: 0.7124\n",
            "Accuracy of the network on validation images: 0.5873, loss: 1.6711, Tree loss: 1.2732\n",
            "Epoch [42/100] - Loss: 0.8085, Accuracy: 0.7216\n",
            "Accuracy of the network on validation images: 0.5925, loss: 1.6513, Tree loss: 1.2692\n",
            "Epoch [43/100] - Loss: 0.7969, Accuracy: 0.7289\n",
            "Accuracy of the network on validation images: 0.5925, loss: 1.6605, Tree loss: 1.2777\n",
            "Epoch [44/100] - Loss: 0.8015, Accuracy: 0.7292\n",
            "Accuracy of the network on validation images: 0.5915, loss: 1.6704, Tree loss: 1.2810\n",
            "Epoch [45/100] - Loss: 0.7703, Accuracy: 0.7334\n",
            "Accuracy of the network on validation images: 0.5981, loss: 1.6840, Tree loss: 1.2643\n",
            "Epoch [46/100] - Loss: 0.7705, Accuracy: 0.7381\n",
            "Accuracy of the network on validation images: 0.5980, loss: 1.6817, Tree loss: 1.2538\n",
            "Epoch [47/100] - Loss: 0.7763, Accuracy: 0.7365\n",
            "Accuracy of the network on validation images: 0.5929, loss: 1.6912, Tree loss: 1.2810\n",
            "Epoch [48/100] - Loss: 0.7562, Accuracy: 0.7422\n",
            "Accuracy of the network on validation images: 0.5946, loss: 1.7122, Tree loss: 1.2827\n",
            "Epoch [49/100] - Loss: 0.7384, Accuracy: 0.7480\n",
            "Accuracy of the network on validation images: 0.5974, loss: 1.7498, Tree loss: 1.2972\n",
            "Epoch [50/100] - Loss: 0.7131, Accuracy: 0.7535\n",
            "Accuracy of the network on validation images: 0.5948, loss: 1.7555, Tree loss: 1.3002\n",
            "Epoch [51/100] - Loss: 0.7089, Accuracy: 0.7565\n",
            "Accuracy of the network on validation images: 0.6028, loss: 1.7051, Tree loss: 1.2801\n",
            "Epoch [52/100] - Loss: 0.7052, Accuracy: 0.7567\n",
            "Accuracy of the network on validation images: 0.6018, loss: 1.7569, Tree loss: 1.3083\n",
            "Epoch [53/100] - Loss: 0.6873, Accuracy: 0.7599\n",
            "Accuracy of the network on validation images: 0.6024, loss: 1.7364, Tree loss: 1.2898\n",
            "Epoch [54/100] - Loss: 0.6969, Accuracy: 0.7610\n",
            "Accuracy of the network on validation images: 0.6051, loss: 1.7394, Tree loss: 1.2869\n",
            "Epoch [55/100] - Loss: 0.6896, Accuracy: 0.7652\n",
            "Accuracy of the network on validation images: 0.5943, loss: 1.6927, Tree loss: 1.2731\n",
            "Epoch [56/100] - Loss: 0.6784, Accuracy: 0.7709\n",
            "Accuracy of the network on validation images: 0.6026, loss: 1.7187, Tree loss: 1.2820\n",
            "Epoch [57/100] - Loss: 0.6651, Accuracy: 0.7735\n",
            "Accuracy of the network on validation images: 0.6032, loss: 1.7499, Tree loss: 1.3061\n",
            "Epoch [58/100] - Loss: 0.6521, Accuracy: 0.7761\n",
            "Accuracy of the network on validation images: 0.6076, loss: 1.7377, Tree loss: 1.2697\n",
            "Epoch [59/100] - Loss: 0.6590, Accuracy: 0.7754\n",
            "Accuracy of the network on validation images: 0.5953, loss: 1.7670, Tree loss: 1.2786\n",
            "Epoch [60/100] - Loss: 0.6355, Accuracy: 0.7812\n",
            "Accuracy of the network on validation images: 0.5958, loss: 1.8156, Tree loss: 1.3187\n",
            "Epoch [61/100] - Loss: 0.6499, Accuracy: 0.7778\n",
            "Accuracy of the network on validation images: 0.6066, loss: 1.7638, Tree loss: 1.2852\n",
            "Epoch [62/100] - Loss: 0.6342, Accuracy: 0.7803\n",
            "Accuracy of the network on validation images: 0.5964, loss: 1.8095, Tree loss: 1.3084\n",
            "Epoch [63/100] - Loss: 0.6132, Accuracy: 0.7852\n",
            "Accuracy of the network on validation images: 0.6037, loss: 1.8472, Tree loss: 1.3231\n",
            "Epoch [64/100] - Loss: 0.6065, Accuracy: 0.7867\n",
            "Accuracy of the network on validation images: 0.6004, loss: 1.7253, Tree loss: 1.2614\n",
            "Epoch [65/100] - Loss: 0.6081, Accuracy: 0.7859\n",
            "Accuracy of the network on validation images: 0.6134, loss: 1.8062, Tree loss: 1.2698\n",
            "Epoch [66/100] - Loss: 0.6054, Accuracy: 0.7891\n",
            "Accuracy of the network on validation images: 0.6016, loss: 1.7559, Tree loss: 1.2702\n",
            "Epoch [67/100] - Loss: 0.6112, Accuracy: 0.7896\n",
            "Accuracy of the network on validation images: 0.6030, loss: 1.7525, Tree loss: 1.2852\n",
            "Epoch [68/100] - Loss: 0.5999, Accuracy: 0.7919\n",
            "Accuracy of the network on validation images: 0.6112, loss: 1.8010, Tree loss: 1.2840\n",
            "Epoch [69/100] - Loss: 0.5808, Accuracy: 0.7964\n",
            "Accuracy of the network on validation images: 0.6001, loss: 1.7515, Tree loss: 1.2838\n",
            "Epoch [70/100] - Loss: 0.5849, Accuracy: 0.7949\n",
            "Accuracy of the network on validation images: 0.5969, loss: 1.8033, Tree loss: 1.3101\n",
            "Epoch [71/100] - Loss: 0.5722, Accuracy: 0.8006\n",
            "Accuracy of the network on validation images: 0.6132, loss: 1.7634, Tree loss: 1.2788\n",
            "Epoch [72/100] - Loss: 0.5747, Accuracy: 0.7999\n",
            "Accuracy of the network on validation images: 0.6027, loss: 1.7883, Tree loss: 1.2758\n",
            "Epoch [73/100] - Loss: 0.5524, Accuracy: 0.8038\n",
            "Accuracy of the network on validation images: 0.6161, loss: 1.8222, Tree loss: 1.2781\n",
            "Epoch [74/100] - Loss: 0.5735, Accuracy: 0.8024\n",
            "Accuracy of the network on validation images: 0.6092, loss: 1.7768, Tree loss: 1.2734\n",
            "Epoch [75/100] - Loss: 0.5786, Accuracy: 0.7994\n",
            "Accuracy of the network on validation images: 0.6071, loss: 1.8187, Tree loss: 1.3034\n",
            "Epoch [76/100] - Loss: 0.5715, Accuracy: 0.8008\n",
            "Accuracy of the network on validation images: 0.6045, loss: 1.8257, Tree loss: 1.2883\n",
            "Epoch [77/100] - Loss: 0.5703, Accuracy: 0.8023\n",
            "Accuracy of the network on validation images: 0.6098, loss: 1.7591, Tree loss: 1.2649\n",
            "Epoch [78/100] - Loss: 0.5235, Accuracy: 0.8128\n",
            "Accuracy of the network on validation images: 0.6138, loss: 1.7884, Tree loss: 1.2402\n",
            "Epoch [79/100] - Loss: 0.5373, Accuracy: 0.8106\n",
            "Accuracy of the network on validation images: 0.6055, loss: 1.8224, Tree loss: 1.2921\n",
            "Epoch [80/100] - Loss: 0.5240, Accuracy: 0.8136\n",
            "Accuracy of the network on validation images: 0.6199, loss: 1.7915, Tree loss: 1.2654\n",
            "Epoch [81/100] - Loss: 0.5136, Accuracy: 0.8161\n",
            "Accuracy of the network on validation images: 0.6099, loss: 1.8209, Tree loss: 1.2819\n",
            "Epoch [82/100] - Loss: 0.5331, Accuracy: 0.8149\n",
            "Accuracy of the network on validation images: 0.6191, loss: 1.8624, Tree loss: 1.2735\n",
            "Epoch [83/100] - Loss: 0.4984, Accuracy: 0.8204\n",
            "Accuracy of the network on validation images: 0.6147, loss: 1.7972, Tree loss: 1.2656\n",
            "Epoch [84/100] - Loss: 0.5034, Accuracy: 0.8194\n",
            "Accuracy of the network on validation images: 0.6076, loss: 1.8327, Tree loss: 1.2815\n",
            "Epoch [85/100] - Loss: 0.5265, Accuracy: 0.8156\n",
            "Accuracy of the network on validation images: 0.6041, loss: 1.8657, Tree loss: 1.2879\n",
            "Epoch [86/100] - Loss: 0.5247, Accuracy: 0.8173\n",
            "Accuracy of the network on validation images: 0.6165, loss: 1.7646, Tree loss: 1.2435\n",
            "Epoch [87/100] - Loss: 0.5027, Accuracy: 0.8221\n",
            "Accuracy of the network on validation images: 0.6073, loss: 1.8718, Tree loss: 1.2867\n",
            "Epoch [88/100] - Loss: 0.5025, Accuracy: 0.8240\n",
            "Accuracy of the network on validation images: 0.6145, loss: 1.8662, Tree loss: 1.2844\n",
            "Epoch [89/100] - Loss: 0.5062, Accuracy: 0.8213\n",
            "Accuracy of the network on validation images: 0.6105, loss: 1.8482, Tree loss: 1.2881\n",
            "Epoch [90/100] - Loss: 0.4759, Accuracy: 0.8289\n",
            "Accuracy of the network on validation images: 0.6185, loss: 1.8846, Tree loss: 1.2934\n",
            "Epoch [91/100] - Loss: 0.4827, Accuracy: 0.8294\n",
            "Accuracy of the network on validation images: 0.6100, loss: 1.8649, Tree loss: 1.3044\n",
            "Epoch [92/100] - Loss: 0.4777, Accuracy: 0.8285\n",
            "Accuracy of the network on validation images: 0.6101, loss: 1.8147, Tree loss: 1.2612\n",
            "Epoch [93/100] - Loss: 0.4930, Accuracy: 0.8265\n",
            "Accuracy of the network on validation images: 0.6091, loss: 1.9107, Tree loss: 1.3078\n",
            "Epoch [94/100] - Loss: 0.4847, Accuracy: 0.8283\n",
            "Accuracy of the network on validation images: 0.6159, loss: 1.8343, Tree loss: 1.2745\n",
            "Epoch [95/100] - Loss: 0.4703, Accuracy: 0.8310\n",
            "Accuracy of the network on validation images: 0.6194, loss: 1.8711, Tree loss: 1.2768\n",
            "Epoch [96/100] - Loss: 0.4708, Accuracy: 0.8324\n",
            "Accuracy of the network on validation images: 0.6115, loss: 1.7970, Tree loss: 1.2250\n",
            "Epoch [97/100] - Loss: 0.4694, Accuracy: 0.8324\n",
            "Accuracy of the network on validation images: 0.6095, loss: 1.8621, Tree loss: 1.2792\n",
            "Epoch [98/100] - Loss: 0.4752, Accuracy: 0.8326\n",
            "Accuracy of the network on validation images: 0.6123, loss: 1.8802, Tree loss: 1.2931\n",
            "Epoch [99/100] - Loss: 0.4573, Accuracy: 0.8337\n",
            "Accuracy of the network on validation images: 0.6165, loss: 1.8807, Tree loss: 1.2674\n",
            "Epoch [100/100] - Loss: 0.4842, Accuracy: 0.8302\n",
            "Accuracy of the network on validation images: 0.6099, loss: 1.8389, Tree loss: 1.2696\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Testing\n",
        "model.load_state_dict(BEST_MODEL)\n",
        "\n",
        "total_test_step=len(test_loader)\n",
        "\n",
        "with torch.no_grad():\n",
        "    test_acc=0\n",
        "    test_loss=0\n",
        "    Tree_Loss_Value=0\n",
        "\n",
        "    for i, (images, target) in enumerate(test_loader, 1):\n",
        "        \n",
        "        y_true = target[0]\n",
        "        y_trans = target[1]\n",
        "        \n",
        "        images = images.to(device)\n",
        "        y_true = y_true.to(device)\n",
        "        y_trans = y_trans.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        \n",
        "        # Loss\n",
        "        test_loss += criterion(outputs,y_trans)\n",
        "        Tree_Loss_Value += tLoss(outputs,y_true)\n",
        "        test_acc += get_accuracy(outputs, y_true)\n",
        "\n",
        "    print(f'Accuracy of the network on test images: {(test_acc/total_test_step):.4f}, loss: {(test_loss/total_test_step):.4f}, Tree loss: {(Tree_Loss_Value/total_test_step):.4f}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-22T12:04:58.949898Z",
          "iopub.status.idle": "2022-09-22T12:04:58.950661Z",
          "shell.execute_reply.started": "2022-09-22T12:04:58.950401Z",
          "shell.execute_reply": "2022-09-22T12:04:58.950429Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbirVi5kGcYD",
        "outputId": "ce07ff18-c90b-495a-da01-ed3e54d829e4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on test images: 0.6283, loss: 1.7812, Tree loss: 1.2093\n"
          ]
        }
      ]
    }
  ]
}