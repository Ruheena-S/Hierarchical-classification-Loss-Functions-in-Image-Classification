{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "600c162af5694597a870f7bd253392fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d703f5ae353f4669a0202894a8924f83",
              "IPY_MODEL_5453ff60421049b08a736e02b6d19d1f",
              "IPY_MODEL_a6e430f125e34b24bf59a456b8d282df"
            ],
            "layout": "IPY_MODEL_66a975077f2b415b86950b88aa58e2c7"
          }
        },
        "d703f5ae353f4669a0202894a8924f83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_528826036bab4b40bdf0603d705c5f7b",
            "placeholder": "​",
            "style": "IPY_MODEL_1c625cd48abd4d2f947c44509aaec4ed",
            "value": "100%"
          }
        },
        "5453ff60421049b08a736e02b6d19d1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21f32a7ad40f4cf1a0cfd1c554f1cf6e",
            "max": 169001437,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f1463848620743ba9ad780dece89cc37",
            "value": 169001437
          }
        },
        "a6e430f125e34b24bf59a456b8d282df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75c0ad3722084fdbb20777ee4bc10fb6",
            "placeholder": "​",
            "style": "IPY_MODEL_b3bff68ed80742f09cff99d6ddb4205a",
            "value": " 169001437/169001437 [00:06&lt;00:00, 52212547.15it/s]"
          }
        },
        "66a975077f2b415b86950b88aa58e2c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "528826036bab4b40bdf0603d705c5f7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c625cd48abd4d2f947c44509aaec4ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21f32a7ad40f4cf1a0cfd1c554f1cf6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1463848620743ba9ad780dece89cc37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "75c0ad3722084fdbb20777ee4bc10fb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3bff68ed80742f09cff99d6ddb4205a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "826b824e3ed64eaead4b709511924383": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7a291ecfe41144b48c2303d3d2c24e2d",
              "IPY_MODEL_2faa1c47e9264f9daa36e59a9c2e7cd2",
              "IPY_MODEL_6ba1ae0f3aaa4c0bb0c4b71dba8875f6"
            ],
            "layout": "IPY_MODEL_3fb905002f8e42aba312d54aa29070a3"
          }
        },
        "7a291ecfe41144b48c2303d3d2c24e2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_667b7c1bfc684006b77de0d222ed1612",
            "placeholder": "​",
            "style": "IPY_MODEL_0d39ff23b5a8443998cfca40b9dec46d",
            "value": "100%"
          }
        },
        "2faa1c47e9264f9daa36e59a9c2e7cd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2053e130ce92422c802c23488545228c",
            "max": 553433881,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_80441ff29ba644d88542bfd2e7c9547f",
            "value": 553433881
          }
        },
        "6ba1ae0f3aaa4c0bb0c4b71dba8875f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41f4209b0f544656b27e630ba4837449",
            "placeholder": "​",
            "style": "IPY_MODEL_03ac24ea900a4c898262795d99fcb4a7",
            "value": " 528M/528M [00:03&lt;00:00, 246MB/s]"
          }
        },
        "3fb905002f8e42aba312d54aa29070a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "667b7c1bfc684006b77de0d222ed1612": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d39ff23b5a8443998cfca40b9dec46d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2053e130ce92422c802c23488545228c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80441ff29ba644d88542bfd2e7c9547f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "41f4209b0f544656b27e630ba4837449": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03ac24ea900a4c898262795d99fcb4a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ruheena-S/Hierarchical-classification-Loss-Functions-in-Image-Classification/blob/main/VGG16_CE_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torch_optimizer torchmetrics\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUw-iyyEGu_h",
        "outputId": "ddbc6d61-2003-4729-8ca2-66dba99b0e20"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch_optimizer\n",
            "  Downloading torch_optimizer-0.3.0-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 527 kB/s \n",
            "\u001b[?25hCollecting torchmetrics\n",
            "  Downloading torchmetrics-0.9.3-py3-none-any.whl (419 kB)\n",
            "\u001b[K     |████████████████████████████████| 419 kB 14.7 MB/s \n",
            "\u001b[?25hCollecting pytorch-ranger>=0.1.1\n",
            "  Downloading pytorch_ranger-0.1.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from torch_optimizer) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.5.0->torch_optimizer) (4.1.1)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.9)\n",
            "Installing collected packages: pytorch-ranger, torchmetrics, torch-optimizer\n",
            "Successfully installed pytorch-ranger-0.1.1 torch-optimizer-0.3.0 torchmetrics-0.9.3\n",
            "Tue Sep 20 09:28:35 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PokSv1_2Hjit",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89c4f1ce-2d36-4273-91fd-44f275d1a71c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f4ea34174d0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_optimizer import Ranger\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms,models\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "from torchmetrics import Accuracy\n",
        "from torch.optim.lr_scheduler import CyclicLR\n",
        "\n",
        "torch.manual_seed(43)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "KCEDW_c6Hltf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data pre-processing**"
      ],
      "metadata": {
        "id": "J0QP7OZpNT_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(size=[32,32], padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.CenterCrop(size=[32,32]),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "dataset = datasets.CIFAR100(root='data/', download=True, transform=transform_train)\n",
        "test_dataset = datasets.CIFAR100(root='data/', train=False, transform=transform_test)\n",
        "\n",
        "\n",
        "val_size = 5000\n",
        "train_size = len(dataset) - val_size\n",
        "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
        "batch_size=256\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4)\n",
        "valid_loader = DataLoader(val_ds, batch_size, num_workers=4)\n",
        "test_loader = DataLoader(test_dataset, batch_size, num_workers=4)"
      ],
      "metadata": {
        "id": "i3-rRz8yyDWz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "600c162af5694597a870f7bd253392fa",
            "d703f5ae353f4669a0202894a8924f83",
            "5453ff60421049b08a736e02b6d19d1f",
            "a6e430f125e34b24bf59a456b8d282df",
            "66a975077f2b415b86950b88aa58e2c7",
            "528826036bab4b40bdf0603d705c5f7b",
            "1c625cd48abd4d2f947c44509aaec4ed",
            "21f32a7ad40f4cf1a0cfd1c554f1cf6e",
            "f1463848620743ba9ad780dece89cc37",
            "75c0ad3722084fdbb20777ee4bc10fb6",
            "b3bff68ed80742f09cff99d6ddb4205a"
          ]
        },
        "outputId": "859a7bdb-a975-45c5-82da-bd6c2cf30045"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/169001437 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "600c162af5694597a870f7bd253392fa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/cifar-100-python.tar.gz to data/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 100\n",
        "num_epochs = 100"
      ],
      "metadata": {
        "id": "azgBL8En5LQq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VGGForCiFar100(nn.Module):\n",
        "  def __init__(self, hid_dim=5000, dropout=0.5, n_classes=100, use_fc=True, freeze=False):\n",
        "    super().__init__()\n",
        "    self.vgg = models.vgg16(pretrained=True)\n",
        "    if not use_fc:\n",
        "      self.vgg.classifier = nn.Linear(512 * 7 * 7, n_classes)\n",
        "    else:\n",
        "      self.vgg.classifier = nn.Sequential(\n",
        "              nn.Linear(512 * 7 * 7, 4096),\n",
        "              nn.ReLU(True),\n",
        "              nn.Dropout(p=dropout),\n",
        "              nn.Linear(4096, 4096),\n",
        "              nn.ReLU(True),\n",
        "              nn.Dropout(p=dropout),\n",
        "              nn.Linear(4096, n_classes),\n",
        "          )\n",
        "      \n",
        "    if freeze:\n",
        "      for param in self.vgg.features.parameters():\n",
        "        param.requires_grad = False\n",
        "      for param in self.vgg.avg_pool.parameters():\n",
        "        param.requires_grad = False\n",
        "      for param in self.vgg.flatten.parameters():\n",
        "        param.requires_grad = False\n",
        "    \n",
        "\n",
        "  def forward(self, x):\n",
        "    return F.log_softmax(self.vgg(x), dim=-1)"
      ],
      "metadata": {
        "id": "GxSco5U2HOFw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**VGG16 Architecture**"
      ],
      "metadata": {
        "id": "ga9_PyubPUS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = VGGForCiFar100(n_classes=num_classes).to(device)\n",
        "criterion = nn.NLLLoss().to(device)\n",
        "accuracy = Accuracy(num_classes=num_classes).to(device)\n",
        "optimizer = Ranger(model.parameters(), lr=1e-3, weight_decay=1e-4) \n",
        "scheduler = CyclicLR(optimizer, base_lr=1e-6, max_lr=1e-3, step_size_up=len(train_loader)//2, cycle_momentum=False)"
      ],
      "metadata": {
        "id": "3IG9OrXd3Wep",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "826b824e3ed64eaead4b709511924383",
            "7a291ecfe41144b48c2303d3d2c24e2d",
            "2faa1c47e9264f9daa36e59a9c2e7cd2",
            "6ba1ae0f3aaa4c0bb0c4b71dba8875f6",
            "3fb905002f8e42aba312d54aa29070a3",
            "667b7c1bfc684006b77de0d222ed1612",
            "0d39ff23b5a8443998cfca40b9dec46d",
            "2053e130ce92422c802c23488545228c",
            "80441ff29ba644d88542bfd2e7c9547f",
            "41f4209b0f544656b27e630ba4837449",
            "03ac24ea900a4c898262795d99fcb4a7"
          ]
        },
        "outputId": "075cdb44-edea-4b5e-fe6a-447ad6b18379"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/528M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "826b824e3ed64eaead4b709511924383"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training and Validation**"
      ],
      "metadata": {
        "id": "MLSzBW0NP5eb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_train_step = len(train_loader)\n",
        "total_val_step=len(valid_loader)\n",
        "BEST_VAL_METRIC = 0\n",
        "BEST_MODEL = None\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "\n",
        "    train_loss=0\n",
        "    train_acc=0\n",
        "    model.train()\n",
        "\n",
        "    for i, (images, target) in enumerate(train_loader, 1):\n",
        "\n",
        "        # Move tensors to the configured device\n",
        "        images = images.to(device)\n",
        "        target = target.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, target)\n",
        "\n",
        "        train_loss += loss\n",
        "        train_acc += accuracy(outputs, target)\n",
        "        \n",
        "        # Backward and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    print(f'Epoch [{epoch}/{num_epochs}] - Loss: {(train_loss/total_train_step):.4f}, Accuracy: {(train_acc/total_train_step):.4f}')\n",
        "\n",
        "    model.eval() \n",
        "    # Validation\n",
        "    with torch.no_grad():\n",
        "        val_acc = 0\n",
        "        val_loss=0\n",
        "        for i, (images, target) in enumerate(valid_loader, 1):\n",
        "            images = images.to(device)\n",
        "            target = target.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            val_loss += criterion(outputs, target)\n",
        "            val_acc += accuracy(outputs, target)\n",
        "\n",
        "    if val_acc/total_val_step > BEST_VAL_METRIC:\n",
        "        BEST_VAL_METRIC = val_acc/total_val_step\n",
        "        BEST_MODEL = model.state_dict() \n",
        "\n",
        "    print(f'Accuracy of the network on the 5000 validation images: {(val_acc/total_val_step):.4f}, loss: {(val_loss/total_val_step):.4f}') "
      ],
      "metadata": {
        "id": "zE0L6pzBKlZW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b981f195-6c40-4aa9-be8e-73a5306ea0ce"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pytorch_ranger/ranger.py:172: UserWarning: This overload of addcmul_ is deprecated:\n",
            "\taddcmul_(Number value, Tensor tensor1, Tensor tensor2)\n",
            "Consider using one of the following signatures instead:\n",
            "\taddcmul_(Tensor tensor1, Tensor tensor2, *, Number value) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1174.)\n",
            "  exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100] - Loss: 3.0451, Accuracy: 0.2620\n",
            "Accuracy of the network on the 5000 validation images: 0.4691, loss: 1.9273\n",
            "Epoch [2/100] - Loss: 1.9695, Accuracy: 0.4654\n",
            "Accuracy of the network on the 5000 validation images: 0.5269, loss: 1.6579\n",
            "Epoch [3/100] - Loss: 1.6835, Accuracy: 0.5352\n",
            "Accuracy of the network on the 5000 validation images: 0.5676, loss: 1.5460\n",
            "Epoch [4/100] - Loss: 1.4963, Accuracy: 0.5845\n",
            "Accuracy of the network on the 5000 validation images: 0.5823, loss: 1.4930\n",
            "Epoch [5/100] - Loss: 1.3662, Accuracy: 0.6145\n",
            "Accuracy of the network on the 5000 validation images: 0.6020, loss: 1.4458\n",
            "Epoch [6/100] - Loss: 1.2600, Accuracy: 0.6432\n",
            "Accuracy of the network on the 5000 validation images: 0.6072, loss: 1.4113\n",
            "Epoch [7/100] - Loss: 1.1710, Accuracy: 0.6662\n",
            "Accuracy of the network on the 5000 validation images: 0.6269, loss: 1.3690\n",
            "Epoch [8/100] - Loss: 1.0880, Accuracy: 0.6898\n",
            "Accuracy of the network on the 5000 validation images: 0.6339, loss: 1.3491\n",
            "Epoch [9/100] - Loss: 1.0291, Accuracy: 0.7023\n",
            "Accuracy of the network on the 5000 validation images: 0.6342, loss: 1.3451\n",
            "Epoch [10/100] - Loss: 0.9646, Accuracy: 0.7247\n",
            "Accuracy of the network on the 5000 validation images: 0.6394, loss: 1.3561\n",
            "Epoch [11/100] - Loss: 0.9253, Accuracy: 0.7372\n",
            "Accuracy of the network on the 5000 validation images: 0.6358, loss: 1.3601\n",
            "Epoch [12/100] - Loss: 0.8632, Accuracy: 0.7511\n",
            "Accuracy of the network on the 5000 validation images: 0.6406, loss: 1.4117\n",
            "Epoch [13/100] - Loss: 0.8167, Accuracy: 0.7643\n",
            "Accuracy of the network on the 5000 validation images: 0.6409, loss: 1.4098\n",
            "Epoch [14/100] - Loss: 0.7967, Accuracy: 0.7685\n",
            "Accuracy of the network on the 5000 validation images: 0.6378, loss: 1.4211\n",
            "Epoch [15/100] - Loss: 0.7661, Accuracy: 0.7788\n",
            "Accuracy of the network on the 5000 validation images: 0.6517, loss: 1.3730\n",
            "Epoch [16/100] - Loss: 0.7173, Accuracy: 0.7935\n",
            "Accuracy of the network on the 5000 validation images: 0.6439, loss: 1.4396\n",
            "Epoch [17/100] - Loss: 0.7023, Accuracy: 0.7970\n",
            "Accuracy of the network on the 5000 validation images: 0.6438, loss: 1.4343\n",
            "Epoch [18/100] - Loss: 0.6655, Accuracy: 0.8088\n",
            "Accuracy of the network on the 5000 validation images: 0.6584, loss: 1.4155\n",
            "Epoch [19/100] - Loss: 0.6393, Accuracy: 0.8177\n",
            "Accuracy of the network on the 5000 validation images: 0.6501, loss: 1.4482\n",
            "Epoch [20/100] - Loss: 0.6192, Accuracy: 0.8232\n",
            "Accuracy of the network on the 5000 validation images: 0.6510, loss: 1.4677\n",
            "Epoch [21/100] - Loss: 0.6120, Accuracy: 0.8238\n",
            "Accuracy of the network on the 5000 validation images: 0.6558, loss: 1.4584\n",
            "Epoch [22/100] - Loss: 0.5879, Accuracy: 0.8309\n",
            "Accuracy of the network on the 5000 validation images: 0.6564, loss: 1.4587\n",
            "Epoch [23/100] - Loss: 0.5815, Accuracy: 0.8345\n",
            "Accuracy of the network on the 5000 validation images: 0.6617, loss: 1.4488\n",
            "Epoch [24/100] - Loss: 0.5702, Accuracy: 0.8393\n",
            "Accuracy of the network on the 5000 validation images: 0.6420, loss: 1.5131\n",
            "Epoch [25/100] - Loss: 0.5380, Accuracy: 0.8470\n",
            "Accuracy of the network on the 5000 validation images: 0.6469, loss: 1.5399\n",
            "Epoch [26/100] - Loss: 0.5259, Accuracy: 0.8506\n",
            "Accuracy of the network on the 5000 validation images: 0.6578, loss: 1.5103\n",
            "Epoch [27/100] - Loss: 0.5022, Accuracy: 0.8583\n",
            "Accuracy of the network on the 5000 validation images: 0.6495, loss: 1.5315\n",
            "Epoch [28/100] - Loss: 0.5011, Accuracy: 0.8577\n",
            "Accuracy of the network on the 5000 validation images: 0.6430, loss: 1.5538\n",
            "Epoch [29/100] - Loss: 0.5037, Accuracy: 0.8566\n",
            "Accuracy of the network on the 5000 validation images: 0.6509, loss: 1.5727\n",
            "Epoch [30/100] - Loss: 0.4605, Accuracy: 0.8703\n",
            "Accuracy of the network on the 5000 validation images: 0.6478, loss: 1.5697\n",
            "Epoch [31/100] - Loss: 0.4792, Accuracy: 0.8654\n",
            "Accuracy of the network on the 5000 validation images: 0.6576, loss: 1.5495\n",
            "Epoch [32/100] - Loss: 0.4528, Accuracy: 0.8717\n",
            "Accuracy of the network on the 5000 validation images: 0.6534, loss: 1.5489\n",
            "Epoch [33/100] - Loss: 0.4428, Accuracy: 0.8753\n",
            "Accuracy of the network on the 5000 validation images: 0.6434, loss: 1.6146\n",
            "Epoch [34/100] - Loss: 0.4451, Accuracy: 0.8759\n",
            "Accuracy of the network on the 5000 validation images: 0.6420, loss: 1.6099\n",
            "Epoch [35/100] - Loss: 0.4224, Accuracy: 0.8820\n",
            "Accuracy of the network on the 5000 validation images: 0.6567, loss: 1.5605\n",
            "Epoch [36/100] - Loss: 0.4234, Accuracy: 0.8840\n",
            "Accuracy of the network on the 5000 validation images: 0.6534, loss: 1.5783\n",
            "Epoch [37/100] - Loss: 0.4311, Accuracy: 0.8812\n",
            "Accuracy of the network on the 5000 validation images: 0.6536, loss: 1.6258\n",
            "Epoch [38/100] - Loss: 0.3876, Accuracy: 0.8910\n",
            "Accuracy of the network on the 5000 validation images: 0.6547, loss: 1.5869\n",
            "Epoch [39/100] - Loss: 0.3969, Accuracy: 0.8910\n",
            "Accuracy of the network on the 5000 validation images: 0.6485, loss: 1.6307\n",
            "Epoch [40/100] - Loss: 0.3953, Accuracy: 0.8907\n",
            "Accuracy of the network on the 5000 validation images: 0.6467, loss: 1.6450\n",
            "Epoch [41/100] - Loss: 0.3947, Accuracy: 0.8929\n",
            "Accuracy of the network on the 5000 validation images: 0.6482, loss: 1.6215\n",
            "Epoch [42/100] - Loss: 0.3740, Accuracy: 0.8972\n",
            "Accuracy of the network on the 5000 validation images: 0.6442, loss: 1.6601\n",
            "Epoch [43/100] - Loss: 0.3575, Accuracy: 0.9006\n",
            "Accuracy of the network on the 5000 validation images: 0.6508, loss: 1.6347\n",
            "Epoch [44/100] - Loss: 0.3662, Accuracy: 0.8998\n",
            "Accuracy of the network on the 5000 validation images: 0.6545, loss: 1.6404\n",
            "Epoch [45/100] - Loss: 0.3642, Accuracy: 0.8988\n",
            "Accuracy of the network on the 5000 validation images: 0.6581, loss: 1.6600\n",
            "Epoch [46/100] - Loss: 0.3655, Accuracy: 0.9005\n",
            "Accuracy of the network on the 5000 validation images: 0.6490, loss: 1.6831\n",
            "Epoch [47/100] - Loss: 0.3464, Accuracy: 0.9055\n",
            "Accuracy of the network on the 5000 validation images: 0.6494, loss: 1.7024\n",
            "Epoch [48/100] - Loss: 0.3409, Accuracy: 0.9063\n",
            "Accuracy of the network on the 5000 validation images: 0.6529, loss: 1.7034\n",
            "Epoch [49/100] - Loss: 0.3398, Accuracy: 0.9087\n",
            "Accuracy of the network on the 5000 validation images: 0.6487, loss: 1.7396\n",
            "Epoch [50/100] - Loss: 0.3442, Accuracy: 0.9060\n",
            "Accuracy of the network on the 5000 validation images: 0.6503, loss: 1.7006\n",
            "Epoch [51/100] - Loss: 0.3450, Accuracy: 0.9072\n",
            "Accuracy of the network on the 5000 validation images: 0.6635, loss: 1.6790\n",
            "Epoch [52/100] - Loss: 0.3414, Accuracy: 0.9084\n",
            "Accuracy of the network on the 5000 validation images: 0.6511, loss: 1.6718\n",
            "Epoch [53/100] - Loss: 0.3217, Accuracy: 0.9131\n",
            "Accuracy of the network on the 5000 validation images: 0.6445, loss: 1.7766\n",
            "Epoch [54/100] - Loss: 0.3100, Accuracy: 0.9164\n",
            "Accuracy of the network on the 5000 validation images: 0.6427, loss: 1.7070\n",
            "Epoch [55/100] - Loss: 0.3244, Accuracy: 0.9132\n",
            "Accuracy of the network on the 5000 validation images: 0.6540, loss: 1.7150\n",
            "Epoch [56/100] - Loss: 0.3159, Accuracy: 0.9158\n",
            "Accuracy of the network on the 5000 validation images: 0.6492, loss: 1.7040\n",
            "Epoch [57/100] - Loss: 0.3164, Accuracy: 0.9152\n",
            "Accuracy of the network on the 5000 validation images: 0.6458, loss: 1.6674\n",
            "Epoch [58/100] - Loss: 0.3057, Accuracy: 0.9199\n",
            "Accuracy of the network on the 5000 validation images: 0.6436, loss: 1.7576\n",
            "Epoch [59/100] - Loss: 0.3206, Accuracy: 0.9162\n",
            "Accuracy of the network on the 5000 validation images: 0.6408, loss: 1.7228\n",
            "Epoch [60/100] - Loss: 0.2988, Accuracy: 0.9211\n",
            "Accuracy of the network on the 5000 validation images: 0.6481, loss: 1.7785\n",
            "Epoch [61/100] - Loss: 0.3132, Accuracy: 0.9180\n",
            "Accuracy of the network on the 5000 validation images: 0.6487, loss: 1.7083\n",
            "Epoch [62/100] - Loss: 0.2823, Accuracy: 0.9246\n",
            "Accuracy of the network on the 5000 validation images: 0.6498, loss: 1.8291\n",
            "Epoch [63/100] - Loss: 0.2915, Accuracy: 0.9225\n",
            "Accuracy of the network on the 5000 validation images: 0.6376, loss: 1.8147\n",
            "Epoch [64/100] - Loss: 0.2826, Accuracy: 0.9251\n",
            "Accuracy of the network on the 5000 validation images: 0.6476, loss: 1.7616\n",
            "Epoch [65/100] - Loss: 0.2762, Accuracy: 0.9262\n",
            "Accuracy of the network on the 5000 validation images: 0.6486, loss: 1.7666\n",
            "Epoch [66/100] - Loss: 0.2861, Accuracy: 0.9251\n",
            "Accuracy of the network on the 5000 validation images: 0.6499, loss: 1.7741\n",
            "Epoch [67/100] - Loss: 0.2825, Accuracy: 0.9251\n",
            "Accuracy of the network on the 5000 validation images: 0.6510, loss: 1.7462\n",
            "Epoch [68/100] - Loss: 0.2955, Accuracy: 0.9235\n",
            "Accuracy of the network on the 5000 validation images: 0.6445, loss: 1.7575\n",
            "Epoch [69/100] - Loss: 0.2772, Accuracy: 0.9270\n",
            "Accuracy of the network on the 5000 validation images: 0.6411, loss: 1.8495\n",
            "Epoch [70/100] - Loss: 0.2888, Accuracy: 0.9249\n",
            "Accuracy of the network on the 5000 validation images: 0.6511, loss: 1.8098\n",
            "Epoch [71/100] - Loss: 0.2834, Accuracy: 0.9264\n",
            "Accuracy of the network on the 5000 validation images: 0.6410, loss: 1.8588\n",
            "Epoch [72/100] - Loss: 0.2875, Accuracy: 0.9261\n",
            "Accuracy of the network on the 5000 validation images: 0.6486, loss: 1.7459\n",
            "Epoch [73/100] - Loss: 0.2648, Accuracy: 0.9299\n",
            "Accuracy of the network on the 5000 validation images: 0.6450, loss: 1.8094\n",
            "Epoch [74/100] - Loss: 0.2678, Accuracy: 0.9296\n",
            "Accuracy of the network on the 5000 validation images: 0.6512, loss: 1.8068\n",
            "Epoch [75/100] - Loss: 0.2562, Accuracy: 0.9331\n",
            "Accuracy of the network on the 5000 validation images: 0.6523, loss: 1.8140\n",
            "Epoch [76/100] - Loss: 0.2744, Accuracy: 0.9299\n",
            "Accuracy of the network on the 5000 validation images: 0.6444, loss: 1.7735\n",
            "Epoch [77/100] - Loss: 0.2564, Accuracy: 0.9341\n",
            "Accuracy of the network on the 5000 validation images: 0.6422, loss: 1.8593\n",
            "Epoch [78/100] - Loss: 0.2601, Accuracy: 0.9323\n",
            "Accuracy of the network on the 5000 validation images: 0.6383, loss: 1.8056\n",
            "Epoch [79/100] - Loss: 0.2559, Accuracy: 0.9331\n",
            "Accuracy of the network on the 5000 validation images: 0.6321, loss: 1.8217\n",
            "Epoch [80/100] - Loss: 0.2741, Accuracy: 0.9296\n",
            "Accuracy of the network on the 5000 validation images: 0.6389, loss: 1.7669\n",
            "Epoch [81/100] - Loss: 0.2713, Accuracy: 0.9293\n",
            "Accuracy of the network on the 5000 validation images: 0.6484, loss: 1.8101\n",
            "Epoch [82/100] - Loss: 0.2729, Accuracy: 0.9307\n",
            "Accuracy of the network on the 5000 validation images: 0.6391, loss: 1.8227\n",
            "Epoch [83/100] - Loss: 0.2562, Accuracy: 0.9338\n",
            "Accuracy of the network on the 5000 validation images: 0.6351, loss: 1.8256\n",
            "Epoch [84/100] - Loss: 0.2590, Accuracy: 0.9330\n",
            "Accuracy of the network on the 5000 validation images: 0.6397, loss: 1.8500\n",
            "Epoch [85/100] - Loss: 0.2673, Accuracy: 0.9325\n",
            "Accuracy of the network on the 5000 validation images: 0.6372, loss: 1.8115\n",
            "Epoch [86/100] - Loss: 0.2524, Accuracy: 0.9352\n",
            "Accuracy of the network on the 5000 validation images: 0.6497, loss: 1.7457\n",
            "Epoch [87/100] - Loss: 0.2536, Accuracy: 0.9362\n",
            "Accuracy of the network on the 5000 validation images: 0.6476, loss: 1.8016\n",
            "Epoch [88/100] - Loss: 0.2543, Accuracy: 0.9361\n",
            "Accuracy of the network on the 5000 validation images: 0.6481, loss: 1.8306\n",
            "Epoch [89/100] - Loss: 0.2532, Accuracy: 0.9353\n",
            "Accuracy of the network on the 5000 validation images: 0.6466, loss: 1.8005\n",
            "Epoch [90/100] - Loss: 0.2474, Accuracy: 0.9364\n",
            "Accuracy of the network on the 5000 validation images: 0.6387, loss: 1.8997\n",
            "Epoch [91/100] - Loss: 0.2494, Accuracy: 0.9363\n",
            "Accuracy of the network on the 5000 validation images: 0.6458, loss: 1.8198\n",
            "Epoch [92/100] - Loss: 0.2634, Accuracy: 0.9339\n",
            "Accuracy of the network on the 5000 validation images: 0.6440, loss: 1.7979\n",
            "Epoch [93/100] - Loss: 0.2481, Accuracy: 0.9375\n",
            "Accuracy of the network on the 5000 validation images: 0.6422, loss: 1.8451\n",
            "Epoch [94/100] - Loss: 0.2357, Accuracy: 0.9419\n",
            "Accuracy of the network on the 5000 validation images: 0.6467, loss: 1.8472\n",
            "Epoch [95/100] - Loss: 0.2468, Accuracy: 0.9388\n",
            "Accuracy of the network on the 5000 validation images: 0.6391, loss: 1.8637\n",
            "Epoch [96/100] - Loss: 0.2497, Accuracy: 0.9377\n",
            "Accuracy of the network on the 5000 validation images: 0.6434, loss: 1.8577\n",
            "Epoch [97/100] - Loss: 0.2505, Accuracy: 0.9369\n",
            "Accuracy of the network on the 5000 validation images: 0.6409, loss: 1.8839\n",
            "Epoch [98/100] - Loss: 0.2539, Accuracy: 0.9374\n",
            "Accuracy of the network on the 5000 validation images: 0.6391, loss: 1.8790\n",
            "Epoch [99/100] - Loss: 0.2325, Accuracy: 0.9407\n",
            "Accuracy of the network on the 5000 validation images: 0.6434, loss: 1.8501\n",
            "Epoch [100/100] - Loss: 0.2377, Accuracy: 0.9407\n",
            "Accuracy of the network on the 5000 validation images: 0.6498, loss: 1.8762\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Testing**"
      ],
      "metadata": {
        "id": "531kzJwHQS8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save(BEST_MODEL, \"./vgg16_cifar100_best.pt\")\n",
        "# model.load_state_dict(model.load(\"./vgg16_cifar100_best.pt\"))\n",
        "model.load_state_dict(BEST_MODEL)\n",
        "\n",
        "total_test_step=len(test_loader)\n",
        "\n",
        "with torch.no_grad():\n",
        "    test_acc=0\n",
        "    test_loss=0\n",
        "\n",
        "    for i, (images, target) in enumerate(test_loader, 1):\n",
        "\n",
        "        # Move tensors to the configured device\n",
        "        images = images.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        \n",
        "        # Loss\n",
        "        test_loss += criterion(outputs,target)\n",
        "        test_acc += accuracy(outputs, target)\n",
        "\n",
        "    print(f'Accuracy of the network on test images: {(test_acc/total_test_step):.4f}, loss: {(test_loss/total_test_step):.4f}')"
      ],
      "metadata": {
        "id": "1eV5Njd2K3fn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98e94dd6-a213-440b-d0cd-ce5f3f9ac6fb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on test images: 0.6653, loss: 1.8612\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W50Zq-zsufa7"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}